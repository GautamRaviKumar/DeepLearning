{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT5215: Deep Learning (2023)</span>\n",
    "***\n",
    "*CE/Lecturer (Clayton):*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Lecturer (Malaysia):*  **Dr Lim Chern Hong** | lim.chernhong@monash.edu <br/>  <br/>\n",
    "*Tutor:*  **Mr Tuan Nguyen**  \\[tuan.ng@monash.edu \\] | **Dr Binh Nguyen** \\[binh.nguyen1@monash.edu \\] | **Dr Qiuhong Ke** \\[Qiuhong.Ke@monash.edu  \\] \n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Tutorial 2: Feed-forward Neural Nets with TensorFlow 2.x</span>\n",
    "**The purpose of this tutorial is to demonstrate how to work with an open source software library for developing deep neural networks apllications, called TensorFlow. In this tutorial, we will focus on**:  \n",
    "- ***Inspect the common pipeline of deep learning*.**\n",
    "- ***How to implement a feedforward neural net for a multi-class classfication problem using TF 2.x*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.1 Feedforward Neural Network </span> <span style=\"color:red\">***** (highly important)</span>\n",
    "#### <span style=\"color:#0b486b\"> Tutorial objective </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we consider a fairly realistic deep NNs with *three* layers plus the *output* layer. Its architecture is specified as: $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$, meaning that:\n",
    "- Input size is 16\n",
    "- First layer has 10 hidden units with ReLU activation function\n",
    "- Second layer has 20 hidden units with 20 ReLU activiation function\n",
    "- Third layer has 15 hidden units with 15 ReLU activiation function\n",
    "- And output layer is logit layer with 26 hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network, for example, can take the `letter` dataset input with $16$ features and with $26$ classes (A-Z). **Our objective in this tutorial is to implement this specific network in `TensorFlow 2.x`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">Specifying the Neural Network Architecture </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this network as in the figure below. Note that for readability, the number of hidden units in the figure might not equal exactly to the actual size of the hidden units used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DNN_Pipeline.PNG\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the above figure shows the pipeline of the entire process for feeding a mini-batch of batch size $32$ into the network. Using ***mini-batch*** is a common way to train deep NNs in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us denote the mini-batch by $X_b= \\{(x_1, y_1),\\dots, (x_{32}, y_{32})\\}$. The mini-batch can be stored using a $2D$ tensor with the shape $(32, 16)$. Assume that in this network, we use the activation function $ReLu$ where $ReLu(t)= \\max\\{0, t\\}$. The computation in the forward propagation step is as follows:\n",
    "- Input $X_b$ with mini-batch size of 32\n",
    "- $h_1= ReLu(X_b \\times W^1 + b^1)\\in \\mathbb{R}^{32 \\times 10}$. \n",
    "- $h_2= ReLu(h_1 \\times W^2 + b^2\\in \\mathbb{R}^{32 \\times 20}$. \n",
    "- $h_3= ReLu(h_2 \\times W^3 + b^3\\in \\mathbb{R}^{32 \\times 15}$. \n",
    "- $logits= h_3 \\times W^4 + b^4 \\in \\mathbb{R}^{32 \\times 26}$\n",
    "- $p = softmax(logits) \\in \\mathbb{R}^{32 \\times 26}$ <br>\n",
    "\n",
    "where we note that the activation function is perfomed element-wise and the softmax function is used to transform a vector of scalars to a discrete distribution as: \n",
    "\n",
    "$$softmax(z)=\\big[\\frac{\\exp(z_i)}{\\sum_{j=1}^{26}{\\exp(z_j)}}\\big]_{i=1}^{26}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $k$-th row $p_k$ of the matrix $p$ can represent the probability distribution to classify the data point $x_k$ to the classes $1,2,\\dots,26$. In particular, we have:\n",
    "\n",
    "$$p_{km}= p(y_k=m \\mid x_k)  \\text{ for }  m=1,2,\\dots,26$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\"> Exercise 1</span>** : Explain why the dimension for $h_1$ is $32\\times 10$? Similarly, please work out the dimension for $h2, h3, logits$ and $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">Specifying the Loss Function </span>\n",
    "Essiential to training a deep NN is the concept of the **loss function**. This function tells us how good the network is predicting, and hence we can use this loss to find the network weights in such a way that the loss can be minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification task, a common approach is to use the **cross-entropy** loss function. Given a data-label instance $(x_k,y_k)$ where feature $x_k\\in \\mathbb{R}^{16}$ and the label $y_k \\in \\{1,2,...,26\\}$ is a numeric label (for example if $x_k$ is in the class 2, then $y_k =2 $ and its one-hot vector $1_{y_k}=[0,1,0,...,0]$). The cross-entroty between the classification distribution $p_k$ returned from the NN and true label distribution $y_k$ is defined as:\n",
    "$$cross\\_entropy(1_{y_k}, p_k)=-\\sum_{j=1}^{26}y_{kj}\\log{p_{kj}}=-\\log p_{k,y_k}$$. This loss basically enforces the model to predict the label as close as the true label by minimizing $cross\\_entropy(1_{y_k}, p_k)$\n",
    "\n",
    "The above loss function was applied for each instance. For the entire current mini-batch, our loss function becomes: \n",
    "$$\\min \\sum_{k=1}^{32}cross\\_entropy(1_{y_k}, p_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\"> Exercise 2: </span>** : **<span style=\"color:#0b486b\">In the corss-entropy equation above, $y_k$ is the class for $x_k$, explain why the end result is $-\\log p_{k,y_k}$.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\"> Exercise 3: </span>** : **<span style=\"color:#0b486b\">Let $p=[0.1, 0.3, 0.6]$ and $q=[0.0, 0.5, 0.5]$ be two discrete distributions, what is the $cross\\_entropy(q,p)$ ?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.2 Implementation with TensorFlow 2.x</span> <span style=\"color:red\">***** (highly important)</span>\n",
    "We now shall implement the aforementioned network with the architecture of $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in Tensorflow using the dataset `letter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This letter dataset can be found at [the LIBSVM website](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#letter). Here is the dataset information:\n",
    "-  *The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet. The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli. Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical pipeline process of implementing a deep learning model is as follows:\n",
    "\n",
    "1. **Data processing**: \n",
    "    - Load the dataset and split into train, valid, and test sets.  \n",
    "     \n",
    "2. **Building the model**: \n",
    "    - Build the model using keras layers.\n",
    "     \n",
    "3. **Compiling the model**: \n",
    "    - Compile the model and specify the optimizer, the loss (e.g., cross-entropy loss) you want to optimize, metrics you want to measure. \n",
    "    \n",
    "4. **Training and evalutating**:\n",
    "    - Train the model with specific training set and validation set in a number of epochs.\n",
    "    - Predict on the test set and assess its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">1. Data Processing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (15000, 16)\n",
      "y data shape: (15000, 1)\n",
      "# classes: 26\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26.]\n"
     ]
    }
   ],
   "source": [
    "data_file_name= \"letter_scale.libsvm\"\n",
    "data_file = os.path.abspath(\"./Data/\" + data_file_name)\n",
    "X_data, y_data = load_svmlight_file(data_file)\n",
    "X_data= X_data.toarray()\n",
    "y_data= y_data.reshape(y_data.shape[0],-1)\n",
    "print(\"X data shape: {}\".format(X_data.shape))\n",
    "print(\"y data shape: {}\".format(y_data.shape))\n",
    "print(\"# classes: {}\".format(len(np.unique(y_data))))\n",
    "print(np.unique(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to split the dataset into the train, validation, and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_valid_test_split(data, target, train_size, test_size):\n",
    "    valid_size = 1 - (train_size + test_size)\n",
    "    X1, X_test, y1, y_test = train_test_split(data, target, test_size = test_size, random_state= 33)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X1, y1, test_size = float(valid_size)/(valid_size+ train_size))\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to encode the label in the form of numeric vector. For example, we want to turn $y\\_data=[\"cat\", \"dog\", \"cat\", \"lion\", \"dog\"]$ to $y\\_data=[0,1,0,2,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, in the following segment of code, we use the object `le` as an instance of the class `preprocessing.LabelEncoder()` which supports us to transform catefgorial labels in `y_data` to numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 15 18 ...  0 11 21]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_data.ravel())\n",
    "y_data= le.transform(y_data.ravel())\n",
    "y_data = y_data.ravel()\n",
    "print(y_data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the function defined above to prepare our data for training, validating and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 16) (1500, 16) (1500, 16)\n",
      "(12000,) (1500,) (1500,)\n",
      "lables: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test_split(X_data, y_data, \n",
    "                                                                            train_size=0.8, \n",
    "                                                                            test_size=0.1)\n",
    "y_train= y_train.reshape(-1)\n",
    "y_test= y_test.reshape(-1)\n",
    "y_valid= y_valid.reshape(-1)\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "print(\"lables: {}\".format(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size= int(X_train.shape[0])\n",
    "n_features= int(X_train.shape[1])\n",
    "n_classes= len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">2. Build up the model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build up a feedforward neural network with the architecture: $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                416       \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model.build()\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x1e7006f1cc8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1e7068f3d08>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1e707a4c488>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1e706935788>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n"
     ]
    }
   ],
   "source": [
    "hidden1 = dnn_model.layers[0]\n",
    "hidden1\n",
    "print(hidden1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">3. Compiling Model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">4. Training and Evaluating </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\"> Visualizing Training Progress </span>\n",
    "In this example, we demonstrate two approaches to visualize training progress, using a History object and using TensorBoard.\n",
    "\n",
    "**Using History object:** \n",
    "The `history object` is the output of `fit()` method, which includes the training parameters (history.params), the list of epochs went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics measured at the end of each epoch on the training set and on the validation set (if any). The training needs to be finished before we can visualize using the history output. \n",
    "\n",
    "**Using TensorBoard:**\n",
    "To visualize with TensorBoard, we first need to create a `tensorboard callback` method with specific log directory. We then pass the callback method to `model.fit()` method. Unlike the previous method, the callback method writes log data to the log file on-the-fly. Therefore, by opening Tensorboard on a separate browser, we can train a model and parallelly visualize the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 1s 99us/sample - loss: 2.9227 - accuracy: 0.1504 - val_loss: 2.1621 - val_accuracy: 0.3907\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 0s 40us/sample - loss: 1.8132 - accuracy: 0.4697 - val_loss: 1.5570 - val_accuracy: 0.5553\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 0s 41us/sample - loss: 1.4817 - accuracy: 0.5742 - val_loss: 1.3794 - val_accuracy: 0.6093\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 1s 42us/sample - loss: 1.3440 - accuracy: 0.6181 - val_loss: 1.2772 - val_accuracy: 0.6453\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 0s 41us/sample - loss: 1.2581 - accuracy: 0.6466 - val_loss: 1.2278 - val_accuracy: 0.6547\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 0s 38us/sample - loss: 1.2022 - accuracy: 0.6628 - val_loss: 1.1756 - val_accuracy: 0.6833\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 1s 42us/sample - loss: 1.1603 - accuracy: 0.6734 - val_loss: 1.1542 - val_accuracy: 0.6793\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 0s 38us/sample - loss: 1.1229 - accuracy: 0.6842 - val_loss: 1.1173 - val_accuracy: 0.6940\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 0s 38us/sample - loss: 1.0951 - accuracy: 0.6888 - val_loss: 1.1090 - val_accuracy: 0.6993\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 1.0714 - accuracy: 0.6982 - val_loss: 1.0805 - val_accuracy: 0.7027\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 0s 39us/sample - loss: 1.0531 - accuracy: 0.7031 - val_loss: 1.0786 - val_accuracy: 0.7013\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 0s 38us/sample - loss: 1.0319 - accuracy: 0.7089 - val_loss: 1.0512 - val_accuracy: 0.7187\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 0s 39us/sample - loss: 1.0150 - accuracy: 0.7107 - val_loss: 1.0275 - val_accuracy: 0.7193\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 0s 38us/sample - loss: 0.9985 - accuracy: 0.7148 - val_loss: 1.0296 - val_accuracy: 0.7173\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 1s 42us/sample - loss: 0.9854 - accuracy: 0.7210 - val_loss: 1.0151 - val_accuracy: 0.7220\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 0s 38us/sample - loss: 0.9716 - accuracy: 0.7235 - val_loss: 1.0030 - val_accuracy: 0.7253\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 0s 40us/sample - loss: 0.9578 - accuracy: 0.7242 - val_loss: 0.9871 - val_accuracy: 0.7180\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 0s 39us/sample - loss: 0.9476 - accuracy: 0.7327 - val_loss: 0.9757 - val_accuracy: 0.7320\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 0s 40us/sample - loss: 0.9315 - accuracy: 0.7368 - val_loss: 0.9588 - val_accuracy: 0.7327\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 0s 40us/sample - loss: 0.9216 - accuracy: 0.7360 - val_loss: 0.9534 - val_accuracy: 0.7333\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "logdir = \"tf_logs/\"\n",
    "\n",
    "# Init a tensorboard_callback \n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "# Call the fit method, passing the tensorboard_callback \n",
    "history = dnn_model.fit(x=X_train, y=y_train, batch_size=32, \n",
    "                        epochs=20, \n",
    "                        validation_data=(X_valid, y_valid), \n",
    "                        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate the trained model on the testing set or any subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 19us/sample - loss: 0.9625 - accuracy: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9624953330357869, 0.73]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(X_test, y_test)  #return loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the trained model to predict $11$-th example in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.reshape(X_test[10, :], (1,-1))\n",
    "y_prob = dnn_model.predict(X_new)\n",
    "y_prob.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predeiction !\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(dnn_model.predict(X_new), axis=-1)\n",
    "if y_pred[0]==y_test[10]:\n",
    "    print(\"Correct predeiction !\")\n",
    "else:\n",
    "    print(\"Incorrect prediction !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">5. Visualizing the Performance and Loss Objective Function </span>\n",
    "\n",
    "The `fit()` method returns a `History object` containing the training parameters (`history.params`), the list of epochs it went through (`history.epoch`), and most importantly a dictionary (`history.history`) containing the loss (`sparse_categorical_crossentropy`) and extra metrics (`accuracy`) as set when compiling model.\n",
    "There are four keys in the history dictionary: `loss` and `val_loss` measure the loss on the training set and the validation set, respectively, while `accuracy` and `val_accuracy` measure the accuracy on the training set and the validation set.  \n",
    "The following figure visualize all four metrics with two y-axes, losses (blue lines, in descending) and accuracies (red lines, in asending) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAEwCAYAAAATusOSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABdsElEQVR4nO3dd3zTVffA8c/tolBm2VOmFmTIEFRkPwJFEAcCDtzyoI+o/PRxizzuvScOEAUBRQQRUVAQlY2yW4YMqcyySyml7f39cRKStmmblKRp2vN+vb6vJN+VGwL09N5zzzXWWpRSSimlAi0s2A1QSimlVOmgQYdSSimlioQGHUoppZQqEhp0KKWUUqpIaNChlFJKqSKhQYdSSimlikTAgg5jiDaGZcaw2hjWG8P/PJxjjOFNY9hiDGuMoZ3bsb7GsNFx7KFAtVMppZRSRSMigPc+CfS0lhRjiAR+M4bvrWWJ2znxQDPH1gl4D+hkDOHAO8AlQBKw3BhmWsuG/N4wLCzMli1bNhCfRSmllCp2UlNTrbU2ZEYtAhZ0WIsFUhwvIx1bzkpkA4EJjnOXGENlY6gNNAS2WMtWAGOY7Dg336CjbNmyHD9+3H8fQimllCrGjDEngt0GXwQ0OjKGcGNYBewD5lrL0hyn1AV2ur1OcuzLa79SSimlQlRAgw5rybSW84B6QEdjaJnjFOPpsnz252IMw41hhTGsyMg4o+YqpZRSKoCKZBzIWg4DC4C+OQ4lAfXdXtcDduWz39O9x1pLB2vpEBHIDBWllFJKnZGA/Zg2hurAKWs5bAxlgX8BL+Q4bSZwlyNnoxNwxFp2G8N+oJkxNAL+AYYC1waqrUoppbI7deoUSUlJpKWlBbspCoiOjqZevXpERkYGuylnJJB9A7WBTx0zUcKAqdYyyxhGAFjL+8BsoB+wBUgFbnYcyzCGu4AfgHDgE2tZH8C2KqWUcpOUlESFChVo2LAhxnga8VZFxVrLgQMHSEpKolGjRsFuzhkxJWlp+5iYGKuzV5RS6swlJCQQFxenAUcxYa0lMTGR5s2bZ9tvjEm11sYEqVk+C5m5vUoppYqWBhzFR0n5LjToUEopVSyVL18+2E1QfqZBh1JKKaWKhE4yVUopVaxZa3nggQf4/vvvMcbw2GOPMWTIEHbv3s2QIUM4evQoGRkZvPfee1x00UXceuutrFixAmMMt9xyC6NGjcr/DTIz4cAB2L8fGjaEmBjYsgV+/RUiIlxbZCR07w6VK8M//8g57sciIuCcc6BMGThyRDbn/ogIiI6GUr5UhwYdeXjiCYiKgkcfDXZLlFKqdPv6669ZtWoVq1evJjk5mfPPP5+uXbsyadIk+vTpw6OPPkpmZiapqamsWrWKf/75h3XLl8OmTaRs2wZffCEBxf79cO210Lw5LFgAd9wh+w4eBOekil9+ga5dYdEiuOWW3I1ZtUqCjm++gbvuyn18yxZo0gTefx8eyrFW6eWXw/Tpfv2zCTU6eyUP8fGwbx+sXOmX2ymlVEhJSEjINlOie/fc5wweDHfeCamp0K9f7uM33SRbcjIMGpT92IIFBbehfPnypKSkMGrUKFq1asUtjiBg2LBhXBsfT7OlS/nr449pVaECsRERRKenk3bJJTw/Zw7d6talx5o1uW961VXQrBns3i2BRXS09Ew4txo1pHfi5Ek4fhwyMqQn5NQpeR4dLQFKaiqkpMixzEzXeeXKQVYWnDgh52RmyuusLHn/l16Cf/+74A/vQc7vBEJv9or2dOQhLg4WLpS/J2Ga+aKUUkWusrXw229cuGYN565dCxMnQpcu9E5MpMPq1VRfu5amIMGBQ/TEiYwBGS7xZPp0CA+X4Y7w8OzPIyJg82bP+537MjPlMSpKApS87pXX87PPDvwfXDGmPR15+OADGDEC/v4b6tcv+HyllCpJPP1WHTCHD8P69bJVqwZXXgmnTnEqKgpn/c0MYwiPjMSkp8vrxo1Ja9uWstdfT3irVnz86af8/c8/3P1//0dU2bJUqFKFNevXM/yOO1iyYoXrh38ITz3Vno4S7Jxz5DExUYMOpVQJY630Dhw+DIcOZd8c+6rv3QsdO8pQRLNmULOm7z+ws7KyDz2kpUn+hPO3/WHD4OefYZfb0lp9+kCtWvDjj+w0hsbGQFYWpyIjWVCmDIuqVaPdQw/Rf+RIpn36KS899hiRkZGUL1+eCRMmkHT0KDcPGkSWYzjjuRdflGETVSxoT0ce9uyBCy+E11+HgQP9ckullPKvkydh714ZSvAQOLB/vySnHTgg+44cgaNHJdfg1Km872sMNiwMk5np2hcWJrkO0dEwcqQEItOnu8ahnQFGtWqwfbtcM2AAzJqV/d5xcZCQIM9HjpQ21akj+RF//QVLlkhbjZGgp3dvCUQ6dZIhilJMezpKsFq1YNu2YLdCKVXkrJXfzMPCpDu+qJ06JcHCnj2y7d3rev7337IdPy77Dx/O+z7h4fIbfmpq7mP33CM/6OfPhzlz5LyYGKhQQbZly0jcsoXm06bJcWdSZEqKvPezz7oSI0Gur1wZqlSR/zwnTpSg5PLLXcFCeLgELc2ayT0WLJDAYtky2LhR7lOvniR69u4N//oXxMb6789VFQva06GUCk3Hj8N338G0afID2dmF796dn9fz/I67/58YFSWzEXJuMTGe9xd0PCpKeh3cgwn3oGL3bhl+KEjPntCihVz722/yw7liRahUSZ4/+SQ0bgx//AErVkggUb68K6ho00YCgPR0V65DDvnmdKSny29lmzfn3v7+O/ufYdWqriGaunUlyPjtN7lH2bLQrZurN6N585DOuQg07eko4V57Tf4/++23YLdEKQVITsCcOTBlCsycKb9916olSVjR0Z5nGxR2n/u0R+d2/Ljr+cGD2Y+lpsr5vihbVn5AWys/hJ0/rIcPl3n7e/fCW29JANGkCZx1lmzdunnXC9C+vWx5iYryrb3u151zjiv5zV1aGmzdmjsYmT9fCmq1bAl33y2BRpcu8r2pUkODjnykpcHvv8sQaMWKwW6NUqXUqVMwbx5MniwFmY4elbyBG26AIUPkB1cwhkFAekaWL3flTjh7LS64AC6+WHoDhg6V/ArHrAsAHn4YHnlErrvuOlcw4dzOPx+qV5dzC1nTIWiio6UXpkWL3Mec001VqaVBRz7i4uRx40b5P0ApVUQyM2XMf8oU6W48eFCGDq66SgKNnj1leMBXWVny20RWlgw3AGzYILkKJ064tlq1JJPcWhg1SoKJ5OTsVS1fekmCjosuyv4eMTEy0+O66yQ46tNH6jlUry5bgwbQqpW8f/nyUqCqtNCAo9TToCMfzqAjMVGDDqUCLitLfgBPngxffSU/6MuXl+ljQ4ZId7y1sHMnrFsHbdvKdU88If9I3YOG5s3hww/leNeusGaN7Hf2NvTtC99/L8/79IGkpOxtGTQIvvxS8gu+/VYenQGD+5BFdDT88IPkLVSvLkFGuXKu+8TEwKefBu7PTKkQo0FHPpo0kcDcmVitlPIzayXRcfJkmDpVfvhHRUmU//bbUlv7hRdgzBi49VbpZQBJSty0SZ4nJEhQUbasbNHRrl4MgEsukQDFudhW2bJyvdOHH0rPivNY2bISRDj99Vf+n6F3b7/8USgVMMb0Bd4AwoGPsPb5HMf/C1zneBUBNAeqY60XWc2+0aAjH1FRsrZA3brBbolSIS4zU4Yndu2S2Q1Ll0rAMXWqJB26S0+XRY+uukp6GLKyZHiiQwep1NegATRq5Dp/6tT83/vxx/M/3rdv4T6TKlac67R4sn37dvr378+6deuKuFXFgDHhwDvAJUASsBxjZmLthtPnWPsS8JLj/AHAqEAEHKBBR4EmTQp2C5QqJC+qTua77+RJibzdF8Py9DosTJI93RfFOnlShjUqVpRpmwsWZJ9GCdKN2KuXzMQ4fhyaNpWAon797GWAn3qq6P7MlCp5OgJbsFaie2MmAwOBDXmcfw3wRaAao0GHF7Ky5BcunT6ugu7oUZl2uGuXPDqfJyfnDhwOHy6w6iSVKklBJ2dhp+bN5TEmxrWa5t69kjNx7JgkXB49KvkRrVtL4PD337l7K8LCpOZERoYkbjoDDmNkqGPwYFl+tGbNwPw5qZD34IMPctZZZ3HnnXcCMGbMGIwxLFy4kEOHDnHq1CmefvppBvpYMjotLY077riDFStWEBERwauvvkqPHj1Yv349N998M+np6WRlZTFt2jTq1KnD4MGDSUpKIjMzk8cff5whQ4YE4uMGUl1gp9vrJKCTxzONKQf0Be4KVGNKVHGw+vXr288++8yv9zx8WGa9tWih5ftV4JjMTCIPHqRMcvLpLSo5mTL792d7HeGhDkRGTAzplSuTUaECGeXLy1ahAqecrytUOH3slPvrcuUgPJzwEyeotGoV5f/6i/JbtlB+yxbK/fMPa59+mgOdOxO7dCmtH3pI3ic2lvQqVUivWpXtN9xAasOGlNm3j3Lbt5NetSrpsbGcqlgx9yyFzEzCHAFQltZlCAlpaWlEO76rnTt9L0FSkLJl81/X6sSJE/z999+c46gFsn79epo1a0ZERARhYWFkZGSQmJhIy5YtAfjzzz9p60wuziE9PZ0tW7bQokUL9u7dy4kTJ2jYsCFpaWls3ryZli1bkpSURExMDLGxsTh/Lh45coQjR45w1llnAZCZmUl4EGfguH8nTlf36JG+H9a67RqLtWNPvzLmaqAP1t7meD0M6Ii1I3O9gTFDgOuxdoD/W+94i5IUdASiIunixTIjbtYsuPRSv95alTbbt0uluZ07Xb0Uzm3PnuxlpUGKVNWpI0lFzsecW5060ivhjYwMyYpetUq2Hj0kUXPDBjj3XDmnSRM47zzZrrlGXqenS4+Jt++jSgT36pf33it/ZfzpvPNkbav8NG/enJ9++on9+/dz5513smDBAkaNGsXChQsJCwtj48aNbNu2jVq1anmd03HFFVcwcuRIevbsCUCXLl145513WLduHc888ww33HADV155Jc2aNWPTpk306dOHwYMH079/f7p06eLfPwQfFaoiqTEXAmOwto/j9cMAWPuch3OnA19ibcASCwI2vGIM9YEJQC0gCxhrLW/kOMdjxqy1HDSG7cAxIBPIsJYOgWprftxXm9WgQ/kkPV2CjNmzZXMucgUynOEMHFq29BxQVK8uwxSFceyYLKRVr57kV1x8MaxdK89Buu1iYyXoOOcc+PVXGS7xVAUvKqrwlStViVBQcBAogwYN4quvvmLPnj0MHTqUiRMnsn//flauXElkZOTp3gpf5PWL9rXXXkunTp347rvv6NOnDx999BE9e/Zk5cqVzJ49m4cffpjevXszevRof3y0orQcaIYxjYB/gKHAtbnOMqYS0A24PpCNCWRORwZwn7X8YQwVgJXGMNdaV/KKtZzOmDWGAcAoa3HPmO1hLckBbGOBYmMlcT4xMZitUCHjn3+k/sPs2TB3ruRAREVB9+5SWfJf/5KZF+61HPzhxx+lMqazF2PLFllsa/p0CTCaNpWETWcvxjnnuIprhYdLUKJUMTN06FBuv/12kpOT+eWXX5g6dSo1atQgMjKS+fPns2PHDp/v2bVrVyZOnEjPnj3ZtGnT6SGcrVu30rhxY+6++262bt3KmjVriIuLIzY2luuvv57y5cszfvx4/3/IQLM2A2PuAn5Apsx+grXrMWaE4/j7jjOvAH7E2oAuYBawoMNadgO7Hc+PGUMCktASlIzZMxEXp0GHykNGhizF7ezNWL1a9tevLxUpL71UhjHc60bkx1rppdi7VxI2nUWoxo+XhbL27nVtNWu6FgZ64glph3N45MYboXNn132/KJb/tJTK17nnnsuxY8eoW7cutWvX5rrrrmPAgAF06NCB8847jzhnBUcf3HnnnYwYMYJWrVoRERHB+PHjKVOmDFOmTOHzzz8nMjKSWrVqMXr0aJYvX85///tfwsLCiIyM5L333gvApywC1s4GZufY936O1+OB8YFuSpHkdBhDQ2Ah0NJajno4Xg7JqG3q7Okwhm3AIcACH1jL2JzX5RSoVWY/+kj+//+///P7rVUo2rdPqlDOni2Phw65egv69ZPt3HNzT3c6cECGOJwrix48CP/7nxx7/HGYMEHu7ewujo2Va0Aqcv78s3S71awpj2efLauJghSwql5dFwlSfpPvKrMqKHSVWS8YQ3lgGnCvp4DDYQDwe46hlc7WsssYagBzjSHRWhZ6uP9wYDgEbtj5ttsCc191hqyFGTOkYmVGhpSgdpaidm45X8fG+r7+Q1aWFKty9mYsXy7vXbOmDGH06yfDJpUru65JS5Nhjg4dJCF09Ojc9SbCw2Xhr+ho6Rnp3j17UFGrluvcyZPzn7PdpIlvn0kppYIgoD0dxhAJzAJ+sJZX8zlvOvCltXjMmDWGMUCKtbyc3/sFqqcDpAxCVJT+IllsrFolC3EtWCD5CY0auRbkSk6WYlOeGCOBh3sg4ik4qVZNZpvMni05Gvv3y7WdOsmQSb9+MozhTPR09n4sXSrb6tUy42PVKmjTRtq5dCm0aydJojVrSj2MwiaKKhVgodjTsXbtWoYNG5ZtX5kyZVi6dGmQWuRfJaGnI2BBhzEY4FPgoLXcm895lYBtQH1rOe7YFwOEOXJBYoC5wJPWMie/9wxU0LFtGzRuLMMst97q99srX+zeDY89BuPGSfDw5JMwfLj0Jrg7cUKGJtwDEffN0z5PhbRiY6VMdr9+sjBYtWpy7bJlEkQMHCh5F3PmQHy8TCs9/3zo2FEClF69pACXUiEmFIOOkq4kBB2BHF7pDAwD1hrDKse+R4AGANaSLWPWGXA41ASmO3qTI4BJBQUcgdSggUwA0GTSIDpxAl55BZ5/Xqai3ncfPPpo9iENd2XLynTRevW8u7+1krjjHpRUrSrBQ3i4BDB33SWBxrZtck1YmPRatG8PXbrIomMtWujy3UoplYdAzl75DSiwcLi1jCdHxqy1bAXaBKRhhRAeLjl7GnQEgbUy8+Khh6So1pVXwosv+j+HwRiZYZKUJPU0li2TrXt3ePll1xoi7dvDHXdIL0b79q6CWTEx0KqVf9uklFIljK694qW4OPjzz2C3opRZtEimDDlzIT77TGpN+IO1sGOHzCS54ALZ16KFa7n0ChUkCdS5BHpkpFTzVEopVWgadHgpLg6mTZOCjroGS4Bt3y49G1OmSJnv8eNh2LAzT7r8/Xcp2LV8uWz790uyzl9/yfH77pOZJB07SteWJnkqpZRfadDhpcsvh7POyr08hvKjo0fhuefgtdfkB/7o0fDAA76v+ZGSIlNcly+XWSSffir3mzABPvxQejQuvVSCi/PPd103fLh/P49SKiRkZGQQkTMZXQWE/irnpXbtZOZK2bLBbkkJlJkpwUCzZpIoevXVMszxv/8VHHBY61o2ffp0WcekUiXJxfjvf2VNkT175PiTT8p6JOvWyeyXO+6QIRSlVLF1+eWX0759e84991zGjpUakXPmzKFdu3a0adOGXr16AZCSksLNN99Mq1ataN26NdOmTQOgvFs14K+++oqbbroJgJtuuon/+7//o0ePHjz44IMsW7aMiy66iLZt23LRRRex0TGcmpmZyf3333/6vm+99RY//fQTV1xxxen7zp07lyuvvLIo/jhCnoZ2Pli9Wob2W7QIdktKkHnzJG9j7Vop2z1rVvbeB08yM2Wo5OuvZfviC7m2fHnpjho0SHoxOnSQIltONWsG9rMoVZJ175573+DBcOedkJoq08pzuukm2ZKT5d+luwULvHrbTz75hNjYWE6cOMH555/PwIEDuf3221m4cCGNGjXi4EGpKfnUU09RqVIl1q6VVd4PHTpU4L03bdrEvHnzCA8P5+jRoyxcuJCIiAjmzZvHI488wrRp0xg7dizbtm3jzz//JCIigoMHD1KlShX+85//sH//fqpXr864ceO4+eabvfo8pZ0GHT4YMED+3U2YEOyWlAAbN8L990uQ0bAhTJ0q/ynlV3XzwAGp4PnNN5KPUaYM9O7tWrjskktkU0qVGG+++SbTp08HYOfOnYwdO5auXbvSqFEjAGJjYwGYN28ekydPPn1dlSpVCrz31VdfTbhjivuRI0e48cYb2bx5M8YYTjnq9sybN48RI0acHn5xvt+wYcP4/PPPufnmm1m8eDET9AeDVzTo8IEu/OYHzvVG3n1XxqpeeAHuvlsSOHM6flyqfGZkyG9UFSpIddCePWXqbHy87FNKBV5+PRPlyuV/vFo1r3s2sr/lAubNm8fixYspV64c3bt3p02bNqeHPtxZazEefmlx35fmXNfIIcZt+Pbxxx+nR48eTJ8+ne3bt9Pd0bOT131vvvlmBgwYQHR0NFdffbXmhHhJczp84Aw6imCNvJJj715Zdv2ll+D662WJ9bfflgSZLVskUdQ94Dh8GD7/XIKK6tXhqqsksRSkDv2OHbIOiTMIUUqVWEeOHKFKlSqUK1eOxMRElixZwsmTJ/nll1/Y5ijS5xxe6d27N2+//fbpa53DKzVr1iQhIYGsrKzTPSZ5vVfdunUBsi1h37t3b95//30yMjKyvV+dOnWoU6cOTz/99Ok8EVUwDTp8EBcnq47v3h3slhRDGRmwfj1MmiSBRJ8+smBZrVry/IEH4JdfZGG0Vavg/fdd+RbOlVQBRoyQ6bFLl8Itt8BPP0kyqJNOY1Wq1Ojbty8ZGRm0bt2axx9/nAsuuIDq1aszduxYrrzyStq0acOQIUMAeOyxxzh06BAtW7akTZs2zJ8/H4Dnn3+e/v3707NnT2rXrp3nez3wwAM8/PDDdO7cmczMzNP7b7vtNho0aEDr1q1p06YNkya5lgi77rrrqF+/Pi000c9rRbK0fVEJ5IJvICuL9+olPwd79gzY2xR/hw5JVq37tn69FDEB6ZFo0UIWOjvvPHls3VrKijv9/bfMNvn6a/jtN8nxaNpUKrCdPCmJoBpgKBU0uvZKwe666y7atm3LrUW0KJeuvVLKONf1atcu2C0pIllZUjgrZ4Dx99+uc6pXl8Bi5EgJLtq0kS4hZ3JnTuvWwc03w4oV8rpVK3j8cdfU2LZtA/qRlFLKH9q3b09MTAyvvPJKsJsSUjTo8EGlSjJSUOLt2ydBxHffuZaIDw+XJeQ7d5Ypcs4Ao1at/GecAKSlyZomTZtKhdHISEkgveIKV5lxpZQKIStXrgx2E0KSBh0++v132LVL6leVSN9/L/PqjxyRnIr27aUno0UL3yujWSulzB96SHoy1qyRpeIXLQpEy5VSShVzGnT46P33JR+yxAUdJ07Agw/CW29JVc95885s1dTFi6Xo15IlErS8+qou+a6UUqWcZur5KC5OVlhPSQl2S/xozRqpAvrWW3DPPbJmyZkEHHPnwkUXyfTWceMkf6NHD/+1VymlVEjSoMNHcXHy6FwBPaRlZUkNjPPPl2mrc+bA6697LtRVkCNHpHcDJMB4/XXYvFmGarSHQymlFBp0+MwZdIR8ZdJdu6BvXxkC6dtXejsKkyWbkSFjTs2ayVK8aWkQESE9Jr6uDquUUqpE06DDR02bSvmIkA46vvlG6mb89psEDN98I1NffWGtJJ22aSOrtTZvDrNnF66XRCmlzpD7arKq+NJEUh+VKQMJCbKYacg5flx6NsaOlWIjEye6um58tWKFrCrZtKkU+Ro4sOCps0opVcJlZGToOiz50D+ZQjj77GC3oBBWrIDrrpM8iwcfhCeflMqhvti7V+YMX3ml5IF89ZUsvevrfZRSoeXee2X5An867zzJ/crDgw8+yFlnncWdd94JwJgxYzDGsHDhQg4dOsSpU6d4+umnGThwYIFvlZKSwsCBAz1eN2HCBF5++WWMMbRu3ZrPPvuMvXv3MmLECLZu3QrAe++9R506dejfvz/r1q0D4OWXXyYlJYUxY8bQvXt3LrroIn7//Xcuu+wyzj77bJ5++mnS09OpWrUqEydOpGbNmqSkpDBy5EhWrFiBMYYnnniCw4cPs27dOl5zrDH14YcfkpCQwKuvvnoGf7jFlwYdhbB4MXz5paxhVuxzJDMzpaGPPy6FvH76yfeZJCdOyH8Ozz4rwyo9e0LlyrIYm1JKBcDQoUO59957TwcdU6dOZc6cOYwaNYqKFSuSnJzMBRdcwGWXXeZxFVh30dHRTJ8+Pdd1GzZs4JlnnuH333+nWrVqpxdzu/vuu+nWrRvTp08nMzOTlJSU0wvI5eXw4cP88ssvgCw2t2TJEowxfPTRR7z44ou88sorPPXUU1SqVIm1a9eePi8qKorWrVvz4osvEhkZybhx4/jggw/O9I+v2NKgoxDWr5dJHyNHQqNGwW5NPv7+G264wVVY5IMPoEoV76+3VlZ0feghudfAgfDiixJwKKVKj3x6JAKlbdu27Nu3j127drF//36qVKlC7dq1GTVqFAsXLiQsLIx//vmHvXv3UqtWrXzvZa3lkUceyXXdzz//zKBBg6hWrRoAsbGxAPz8889MmDABgPDwcCpVqlRg0OFceA4gKSmJIUOGsHv3btLT02nk+EExb948Jk+efPq8Ko7/j3v27MmsWbNo3rw5p06dotWZlCwo5gKWSGoM9Y1hvjEkGMN6Y7jHwzndjeGIMaxybKPdjvU1ho3GsMUYHgpUOwsjJGawTJkiyaIrV8L48fLal4ADZN2VYcNkobb58yXhNCTHlpRSoWjQoEF89dVXTJkyhaFDhzJx4kT279/PypUrWbVqFTVr1iQtLa3A++R1nbW2wF4Sp4iICLKysk6/zvm+MW6z9UaOHMldd93F2rVr+eCDD06fm9f73XbbbYwfP55x48Zx8803e9WeUBXI2SsZwH3W0hy4APiPMXha//dXaznPsT0JYAzhwDtAPNACuCaPa4OiWAcdR4/CjTfC0KHS0FWr5LUvSZ6Orj+aNpUZLitWQPfugWitUkrlaejQoUyePJmvvvqKQYMGceTIEWrUqEFkZCTz589nx44dXt0nr+t69erF1KlTOXDgAMDp4ZVevXrx3nvvAZCZmcnRo0epWbMm+/bt48CBA5w8eZJZs2bl+35169YF4NNPPz29v3fv3rz99tunXzt7Tzp16sTOnTuZNGkS11xzjbd/PCEpYEGHtey2lj8cz48BCUBdLy/vCGyxlq3Wkg5MBgrOFioi1arJL//FLuhYvFiSsz7/HEaPhl9/hSZNvL/eWkkwbd1apsMCXHCBLjGvlAqKc889l2PHjlG3bl1q167Nddddx4oVK+jQoQMTJ04kzsvZd3ldd+655/Loo4/SrVs32rRpw//93/8B8MYbbzB//nxatWpF+/btWb9+PZGRkYwePZpOnTrRv3//fN97zJgxXH311XTp0uX00A3AY489xqFDh2jZsiVt2rRh/vz5p48NHjyYzp07nx5yKamMtTbwb2JoCCwEWlrLUbf93YFpQBKwC7jfWtYbwyCgr7Xc5jhvGNDJWu7K731iYmLsceeqqAF28cVS2mL69CJ5u/xlZMDTT8tWv74EHZ07+3aP9HQYPhw+/VR6RsaO1VkpSpViCQkJNG/ePNjNKDX69+/PqFGj6NWrV57nePpOjDGp1tqQqcQY8ERSYyiPBBb3ugccDn8AZ1lLijH0A74BmgGexgI8RkfGMBwYDkX7M/Knn6RmR9AlJ8Nll0kvx7Bh8PbbULGib/c4fFimwc6fLz0djz2mNTeUUqoIHD58mI4dO9KmTZt8A46SIqBBhzFEIgHHRGv5Oudx9yDEWmYbw7vGUA3p+ajvdmo9pCckF2sZC4wFiInxHJgEQrEIOI4elRLm69fDpElQ2LHAH3+U+huffQbXX+/fNiqlVBFZu3Ytw4YNy7avTJkyLF26NEgtKljlypXZFOjFvIzpC7wBhAMfYe3zHs7pDrwORALJWNstEE0JWNBhDAb4GEiwFo9VToyhFrDXWqwxdERyTA4Ah4FmxtAI+AcYClwbqLYWxqZN8Oij0inQpk0QGnDihBTmWr1aZpVceqnv90hJgfLlYfBg6NgRGjb0dyuVUqrItGrVilX+LmIW6oxxTsy4BPmFfjnGzMTaDW7nVAbeBfpi7d8YUyNQzQlkhmBnYBjQ021KbD9jGGEMIxznDALWGcNq4E1gqLVYa8kA7gJ+QBJQp1rL+gC21WdhYVKQ888/g/Dm6ekwaJAkik6YULiA45tvJMhYtkxea8ChlMqhKHL+lHfO4LvoCGzB2q1Ym9fEjGuBr7H2b8eb7SvsmxUkYD0d1vIbnnMz3M95G3g7j2OzgdkBaJpfNGwoOSRFPoMlM1MKfs2eLcW+fB1SsVYK/dx3n/ZuKKXyFB0dzYEDB6hatarXtSxUYFhrOXDgANGFW1CzLrDT7XUS0CnHOWcDkRizAKgAvIG1EwrzZgUpURVJY2NjWbBgQZG936uvyqKqRfaW1nL2K69Q57vv+Ovf/2bn2Wf79OYmM5Omb79N3W++YX/XriQ88ghZGzbAhg0FX6yUKlWstZw6dSpbQSwVPGFhYURGRuaqTVINIjBmhduusVg71u21NxMzIoD2QC+gLLAYY5Zgrd+TTUpU0HHw4EG6F2ERq7fekhzOIuntsBYeeAC++w4eeYQmzzyDDxU4xIcfyrDK/fdT/YUXqK71N5RSKqQlQwbWdsjnFG8mZiQhyaPHgeMYsxBoA2jQUZy0bw+7d0NWVhHUz3ruOXj5ZfjPf6Qehy+slSmwt9wCtWtD//6BaaNSSqniZjnQDGPym5gxA3gbYyKAKGT45bVANKZIioMVlaIsDlak3n5bVpe7/nop3uVLhLN2LYwYAVOnQl1vC8IqpZQKBV4VBzOmHzIdNhz4BGufwRiZ0GHt+45z/gvcDGQh02pfD0h7Nego5iZMkAqhAwfKdJkIHzqnfvxRZrmULw9z5kh5c6WUUiVGqFUk1UH9M5CeLkuTvPVWgN7gm29kSKRnT1li3peA46OPoF8/mZ2ydKkGHEoppYJOg44zEBUFO3fCH38E4Obz5sGQIdChA8yYIdNkvDV+PNx+O/zrX7JKbP36BV6ilFJKBZomkp6huLgAzF5ZvBguvxzOOUfqcZQv79v1l18Of/8NDz8MkZF+bpxSSilVONrTcYacQYffUmPWrJFhkVq1JCcjNta765KT4e67pTx65cqytL0GHEoppYoRDTrOUFycLNK6zx9FYzdvht69ISZGhldq1fL+ugsvlOXoV670Q0OUUkop/9PhlTPUoQNccYV0MJyRnTslByMzU6qMeluefNcuuOgi6Wr5+Wd5rpRSShVDGnScoQsvhK+/PsOb7NsHl1wiXSbz50v3ibdefBEOHZJhmRYtzrAhSimlVOBo0OEnGRm+zWg97fBh6NNHEj9/+AHatfPtTb/7DoYN04BDKaVUsadBhx/Ex8vj99/7eGFqqpQkX78eZs6ELl18uz4iAtatg5QUH99YKaWUKnqaSOoHVaoUYtrsyZNw5ZUyPXbiROjb17frU1OlOlmZMlC1qo9vrpRSShU9DTr8IC4OduyQOMArGRlw3XUynPLhh3D11b6/6QsvSB2PY8d8v1YppZQKAg06/CAuTiaPbN7sxclZWTB8OEybBq++KmXOfXXkCLz5JrRtCxUq+H69UkopFQQadPiBc7JJgUMs1sJ998G4cVK8a9Sowr3hu+9KAuqjjxbueqWUUioINOjwg2bNZOX5xo0LOPHjj+H11+Gee2DMmMK92fHj0kMSHw/t2xfuHkoppVQQ6NL2RalzZ5lp8uefEFbIeO+TT+DWW+H337UQmFJKlXK6tH0plZ4O27blc8LevTJT5corCx9wANx8MyxcqAGHUkqpkKNBh5889BC0bCl5oh7NmiU5HQMHFv5NsrLAGN/reSillFLFQMCCDmOobwzzjSHBGNYbwz0ezrnOGNY4tkXG0Mbt2HZjWGsMq4xhRaDa6S9xcTJlNikpjxNmzoQGDaBNmzxOKEB6Opx3nuSFKKWUUiEokBVJM4D7rOUPY6gArDSGudaywe2cbUA3azlkDPHAWKCT2/Ee1pIcwDb6jfsMlgYNchxMTYW5cyUXw5jCvcHnn8PatVCnzhm1UymllAqWgPV0WMtua/nD8fwYkADUzXHOIms55Hi5BKgXqPYE2jnnyKPHabNz58oytIUdWsnIgGeflXVZfK1cqpRSShUTRbL2ijE0BNoCS/M57VbAffUSC/xoDBb4wFrG5nHv4cBwgKgovzS3UGrUgMqV8wg6ZsyASpWgW7fC3XzKFPjrL1nOtrA9JUoppVSQBXzKrDGUB34BnrEWj4vAG0MP4F3gYms54NhXx1p2GUMNYC4w0loW5vdewZ4yO2ECNG2aY2JJZibUrg3/+hdMmuT7Ta2VDNWwMFi9+sxmviillCpRQm3KbEB7OowhEpgGTMwn4GgNfATEOwMOAGvZ5XjcZwzTgY6Qf9ARbDfc4GHnkiWwf3/hh1aMkWjm+HENOJRSSoW0QM5eMcDHQIK1vJrHOQ2Ar4Fh1rLJbX+MI/kUY4gBegPrAtVWfzl0SNI3si38NmMGREaeWS5G+/bQtesZt08ppZQKpkD+6twZGAb0dEx7XWUM/YxhhDGMcJwzGqgKvJtjamxN4DdjWA0sA76zljkBbKtfLFwIvXvDOvfwaMYM6N5dcjp89f33cNNNEs0opZRSIS5gwyvW8huQb9ajtdwG3OZh/1agkAUtgsd92mzHjo4nmzbB3Xf7fjNr4X//gz17oHx5v7ZTKaWUCoYimb1SWjRuDBERbjNYZsyQx8su8/1mP/0ES5fCe+/J8IxSSikV4nTBNz+Li4Nzz4Vp05AF3tLSYOVK32/UvTts3gxbt0KZMv5uplJKqRIg1Gav6HQIP4uLc/R0OBd4K8yslV9/hV9+gQce0IBDKaVUiaHDK342ZozjiXOBt8IMrTRqBPffD7ff7s+mKaWUUkGlwyseZGXBBx9A/frQv38hb3LZZbBmjax3r1VElVJKBYAOr5QAYWHw2mvwzju+X5uSAp+9f5ysH+dK4OFrwPHUU/D7776/sVJKKVXMadCRh/h4WLBA1mnzxalT8NUd8wg7meZ7PseaNTB6tMxcUUoppUoYDTryEB8vE08WLPDtuipVYGj0DFKjKvleRfSZZ6BCBRg50rfrlFJKqRCgQUceunWD6GgpCuqTzEz6Zs7i94r9fKuvkZgIX34Jd90lkYtSSinlD8b0xZiNGLMFYx7ycLw7xhzBmFWObXSgmqKzV/JQtiz06FGIoGPxYqqc2s+UtIFc4st1zz0nUc6oUT6+oVJKKZUHY8KBd4BLgCRgOcbMxNoNOc78FWsLO3XCa9rTkY9+/WDLFqnR5bUZM8gMj2RqSjz79/twXcuW8PDDUL26r81USiml8tIR2IK1W7E2HZgMFHLZ8zNXono6YmNjWeBrEkY+mjWDl1+GP/+Ef/7x7pqOU6Zw4rw2fP38H6xf78ObnX++PPqx/UoppUq2ahCBMSvcdo3F2rFur+sCO91eJwGdPNzqQoxZDewC7sdaX36Cea1EBR0HDx6ke/fufr3nyJHQpImXwyyJibBzJ+Ueeoh//cvLdiQlSQXSwYMhPPxMmqqUUqqUSYYMrO2Qzyme6jbkLND1B3AW1qZgTD/gG6CZn5qYjQ6vFMCnqbPOBd4GDODll2HSJC+uefFFuOEG77tSlFJKKe8lAfXdXtdDejNcrD2KtSmO57OBSIypFojGaNBRAJ+mzs6YAe3aQf36fP65F0HHnj3w4YcSdDRo4IfWKqWUUtksB5phTCOMiQKGAjOznWFMLYyjkqUxHZHY4EAgGqNBRwG8njq7dy8sWXK6INg557gtcZ+XV16B9HR4KPcMJqWUUuqMWZsB3AX8ACQAU7F2PcaMwJgRjrMGAescOR1vAkPJb40UY6ZhzKUY43MMoWuveOHSS2HjRpnJkqePP4bbboNVq6BNG554Ap5+Go4fl6All+RkaNhQgpSJE/3eZqWUUiVfUNZeMeZfwM3ABcCXwHisLejXbEB7OrwSHw9//VXA1NkZM+Css6B1a0CWuM/KyidQ+ftvWVHu0Uf93l6llFIqYKydh7XXAe2A7cBcjFmEMTdjTL5VMTXo8EJ8vDzmOcRy/DjMzb7AW1wclCmTT35ou3awYQO0aOH39iqllFIBZUxV4CbgNuBP4A0kCJmb32UadHihSROp2ZFn0DF3rmSbui3w1qaNxCJ9+ng4f+lSWY5Wl7xXSikVaoz5GvgVKAcMwNrLsHYK1o4Eyud3qQYdXsp36uyMGVC5crYF3sLC8ii7kZIiSSK33x6gliqllFIB9TbWtsDa57B2d7Yj+dcM0aDDW3lOnc3MhFmzpGZ6jgXe3nwT/v3vHOd/8AEcOAB33x3I5iqllFKB0hxjKp9+ZUwVjLnTmwsDFnQYQ31jmG8MCcaw3hju8XCOMYY3jWGLMawxhnZux/oaw0bHsaDPKe3WTRaBmz07x4HFi2UmysDcpez/+ktqdZyeIHTihNRV79ULLrww4G1WSimlAuB2rD18+pW1hwCvuu8D2dORAdxnLc2RaTX/MYacWZPxSKnVZsBw4D0AY3CuihcPtACu8XBtkcpz1dkZM6SHo2/fXNfExcloyi5n7bfPPpOCYI89FvD2KqWUUgESdrqYGDhXso3y7sIAsZbd1vKH4/kxpChJ3RynDQQmWIu1liVAZWOojWNVPGvZai1BXxXPKdfUWWsl6OjRAypWzHV+XJw8ni4Stn491Ksn3SZKKaVUaPoBmIoxvTCmJ/AFMMebC4skp8MYGgJtgaU5Dnla/a5uPvs93Xu4MawwhhUZGX5rske5ps4mJkoE4mFoBTwEHW+8IYU7dNaKUkqp0PUg8DNwB/Af4CfgAW8uDHjQYQzlgWnAvdZyNOdhD5fYfPbn3mkZay0drKVDRIDXzM01dXamo3z9ZZd5PL9WLakVli3GKFMmoG1USimlAsraLKx9D2sHYe1VWPsB1mZ6c2lAgw5jiEQCjonW8rWHU/Ja/a7gVfGCpF8/mcGSmooMrbRvL0MmHhgDq1fDnXcCu3dLcLJkSVE2VymllPIvY5phzFcYswFjtp7evOBV0GEM9xhDRcdsk4+N4Q9j6F3ANQb4GEiwllfzOG0mcIPjvhcAR6xlN45V8YyhkTF4XhUvSJxTZxdNdyzwlkcvRy7r1sG338rFSimlVOgah0z8yAB6ABOAz7y50NuejlscQyO9gerIQi/PF3BNZ2AY0NMYVjm2fsYwwhicK9vNBrYCW4APgTsBrCXXqnjWst7LtgaUc+rsvo+/lUTSPPI5nKZMgaZNIe3PBNnhTPRQSimlQlNZrP0JMFi7A2vHAD29udDbLAhnVkI/YJy1rHb0ZOTJWn7Dc26G+zkWSULxdGw2EpQUK9HRMlml1oLsC7zlJTJSZrwcXZ5IdOXKULNm0TRUKaWUCow0x7L2mzHmLuAfoIY3F3rb07HSGH5Ego4fjKECkFWoppYAA3oe58LUeRzqNrDAmSjOjo2s9QnQvLnOXFFKKRXq7kXWXbkbaA9cD9zozYXe9nTcCpwHbLWWVGOIRYZYSqWBMXMpSxrfVxjIlQWc26SJrMFyKLMStTo1KpL2KaWUUgEhhcAGY+1/gRR8jAW87em4ENhoLYeN4XrgMeCITw0tQWovncGRsMp8srlLgeeWKQONGsHo1t/Aa68FvnFKKaVUoMjU2PbZKpL6wNuejveANsbQBikA8jGSrVr6Sms6Fnjb3Kwf836JJDUVypXL/5JBgwo+RymllAoRfwIzMOZL4PjpvdZ6Ko2Rjbc9HRmOpM+BwBvW8gZQoRANDX2LFkFyMhFXDeTkSQ+rznrwXKtJPD69HezbF/DmKaWUUgEWCxxAZqwMcGz9vbnQ256OY8bwMDIFtotjQbbIAq4pmWbOhMhI4u7pS9nXpDppv34FXLNqFXb9ejIrVfX6D1wppZQqlqwtdE6ntz8DhwDXIvU69hhDA+Clwr5pyHIu8NazJ9E1KnpeddaDI0sS2HnqbHbMC+fSSwPfTKWUUipgjBmHp6VJrL2loEu9Gl6xlj3ARKCSMfQH0qxlgo/NDH3OBd4cVUhzrTqbh/JJiWywzdm4sQjaqJRSSgXWLOA7x/YTUBGZyVIgb8ugDwaWAVcDg4GlxjCoUE0NZTNmyKMj6HAOq+Tb25GWRviOrewo29y12qxSSikVqqyd5rZNROKClt5c6m0i6aPA+dZyo7XcAHQEHi9ca0NYjgXeGjeGs8+G2fnVTU1JgUGD2NP4Qg06lFJKlUTNgAbenOht0BFmLe5TLw74cG3JsGcPLF2aa62V+Hi3VWc9qVYNpkzh6IV9NehQSikV+ow5hjFHT2/wLfCgN5d6m0g6xxh+AL5wvB5CMVwXJaBmzfK4wFt8PLzxhgQeHmexpKdDVBSXXw7160uZj/DwomiwUkopFQDWFrpkhrE2dwKqxxMNVyErxxpgobVML+ybBkpMTIw9fvx4wScWxoABsHYtbNuWbf2UtDSIjYVbb4W33vJw3bXXSqbp8uWBaZdSSqlSyxiTaq2NKeI3vQL4GWuPOF5XBrpj7TcFXupt0BEKAhZ0HD8uwyTDh0u3Rg79+0NCAmzZ4mE9t7ZtoXZt7HezSU6WzpIaXq3Fp5RSSuUvSEHHKqw9L8e+P7G2bUGX5puXYQzHjOGoh+2YMRw9s1aHkB9/lC6NHEMrTvHxsHWrh6mzWVmwcSPExZGVJfmnr7wS+OYqpZRSAeQpdvAqXSPfk6wtpaXOc5o5EypXhi6eF3iLj5fH77+X2Syn/f03nDgBzZsTHi7HNJlUKaVUiFuBMa8C7yBFwkYCK725sHTNQCkMxwJvXHopRHqu/O6cOpurXkdCgjw2bw5AXJwGHUoppULeSCAdmAJMBU4A//HmQg06CuJY4M1ZECwvHqfO1qsH//d/0KIFAOedJ0MwzlhEKaWUCjnWHsfah7C2g2N7BGu9SqjUoKMgM2ZID0ffvvmeFh9P7lVnW7WSJI7YWEDyUGNi4PnnA9dcpZRSKqCMmeuYseJ8XQVjfvDmUg068uO2wBsVK+Z7arduULZsjiGWv/6SnA6H6tXhm288ToBRSimlAsOYvhizEWO2YMxD+Zx3PsZkYkxBy5xUw9rDp19Zewjwal6mBh35SUyUebB5zFpxFx0tscns2RKrAHDBBXDPPdnO69VLclJL0ExlpZRSxZUx4UjCZzzQArgGY1rkcd4LgDc9FlkY4yp7bkxDPK0664EGHflxLvA2YIBXp2ebOpucLJsjidTd5s2S3/Hbb/5rqlJKKeVBR2AL1m7F2nRgMuDpN+mRwDTItuRJXh4FfsOYzzDmM+AX4GFvGuNtGXSfGcMnQH9gn7W5V58zhv8C17m1ozlQ3VoOGsN24BiQCWRYSwdv3jM2NpYF2ZIqzkzbzz4j7OyzWblli/R4FKBZM3j5ZVi1Co7vWUNbYM2pUxzM0aasLKlgun49ZGT4rblKKaVKmWoQgTEr3HaNxdqxbq/rAjvdXicBnbLdxJi6wBVAT+D8At/U2jkY0wEYDqwCZiAzWAoUsKADGA+8DUzwdNBaXgJeAjCGAcAoaznodkoPa0n25Q0PHjxI9+7dC9XYXPbskWkm//ufT/ccORIaNYI5V0mlsNaDB0PDhrnOS0iAESPghx+gd2//NFkppVTpkgwZWJvfL+Y562RD7qGQ14EHsTYzd1ltT3c0twH3APWQoOMCYDEStOQrYMMr1rIQsgUR+bkG12JyxcO333pc4K0gzqmzp9YkSGZpA8+r/d5+u8Qijzyi+R1KKaUCJgmo7/a6HrArxzkdgMkYsx0YBLyLMZfnc897kB6RHVjbA2gL7PemMUHP6TCGckBfZCzJyQI/GsNKYxhewPXDjWGFMazw61DFzJkSFbRq5dNl/frJ1NllTa6B99+HMM9/xFFR8MQTsHKl1B5TSimlAmA50AxjGmFMFDAUmJntDGsbYW1DrG0IfAXcWcDibWlYmwaAMWWwNhE4x5vGBHJ4xVsDgN9zDK10tpZdxlADmGsMiY6ek1ysZSwwFiAmxrvs2QJlZsKmTdLL4U1Xk5uuXaFcOfhiy/l0fjv/obHrr/eqBIhSSilVONZmYMxdyKyUcOATrF2PMSMcx98vxF2THHU6vgHmYswhcveeeBTQVWaNoSEwy1Miqds504EvrWVSHsfHACnW8nJB7+fXVWatlRob5cr5fOkV8WnErvqZj9Z2wlSr6vXb+RjfKKWUKuWCssps9gZ0AyoBcxyzY/IV1OEVY6gEdEMyX537YoyRheaMIQboDawLRuMKE3AADD0vkY/3XMruiT97df5XX8HFF0N6gV+XUkopVYxY+wvWzvQm4IAABh3G8AWSzXqOMSQZw63GMMIYRriddgXwo7W4d0/UBH4zhtXAMuA7a5kTqHYGQveasrjKz7tz1+jwJCZGlnj5+ONAtkoppZQKroAOrxQ1vw6vnInRo8l86hkuvySVb38sU+Dp1kKXLrBtm5QDKVu2CNqolFIq5AV9eMVHQZ+9UiIlJnKwcmPmLiyTfdXZPBgDzz4Lu3bBu+8GvnlKKaVUMGjQEQgJCdi45pw8CfPne3dJ167Qpw889xykpAS2eUoppVQwFIcpsyXP5MlUSs2kXHdZdfbSS7277MUXYfduyfFQSimlShrN6Qig/v2l3PmWLTodVimllP9pTkdpt24djB0Lx45lX3XWS9bCQw9JtVKllFKqJNGgw9++/x7+/W/IzCQ+3rXLW8ZIQulLL8mjUkopVVJo0OFvCQlQqxZUrkzjxnDOOb4FHQBjxsCpU/DMMwFpoVJKKRUUGnT4W0ICxMWdfulcddabqbNOjRvDbbfJKM3Wrf5volJKKRUMGnT4k7WQmAjNXZVI4+Pxaeqs02OPQUQE/O9/fm6jUkopFSQadPjTvn1w+HC2oMO56qyvQyx160pPxwMP+LeJSimlVLDolFl/O3QIwsKgUqXTu3TqrFJKqUDQKbOlXZUq2QIOgH79fJ8667R7NwwZAitX+ql9SimlVJBo0OFP48bBCy/k2l2YqbNO5crBvHmS46GUUkqFMg06/GnSJPjqq1y7GzWSqbOzZ/t+y0qVpFjYnDnw669+aKNSSikVJBp0+FNCQrYkUnfx8fDLL75NnXX6z3+k9Mejj8oEGaWUUioUadDhL8eOwT//5Bt0FGbqLMgQy+OPS0/Hjz+eYTuVUkqpINFVZv0lMVEe3QqDuXOfOuvtqrPubrsN9u6Ftm3PoI1KKaVUEGlPh7/s3Str0ufR0xEdDT17wrffQmFm9UZFSaGwGjXOsJ1KKaVUkGjQ4S/9+8PRo5Ixmoc774SkJBg4EE6cKNzbLFoEw4ZBZmYh26mUUkoFiQYd/hQWlm/1r/h4+OQT+PlnuPJKyfHw1a5d8PnnMlFGKaWUCiVakdRfhg6FLl1kqkkBPvoIbr8dBgyQGbZRUd6/TVYWnH++FD5NTPTtWqWUUiWLViR1MIZPjGGfMazL43h3YzhiDKsc22i3Y32NYaMxbDGGhwLVRr85dQqmTZPZK1647TZ45x3J77j2WsjI8P6twsLg6adh2zb4+ONCtlcppZQKgkAOr4wH+hZwzq/Wcp5jexLAGMKBd4B4oAVwjTG0CGA7z9yWLRI55JFE6smdd8Jrr0ms4muORt++cPHF8NRThc8NUUoppYpawKbMWstCY2hYiEs7AlusZSuAMUwGBgIb/Ng8/3JOl/Uh6AC4915IT4cHH5RhknHjpCejIMZItfVly7w7XymllCoOgl2n40JjWA3sAu63lvVAXWCn2zlJQKdgNM5rCQnymM/Mlbw88IAklI4eLYHHBx94F0hcdJFsSimlVKgIZtDxB3CWtaQYQz/gG6AZ4Gn6R57ZrsYwHBgOQUyqLFcOunWDChUKdfnjj0vg8cwz8hnefjvfSTDZjB8vdT+8yF9VSimlgiqgs1ccwyuzrKWlF+duBzoggccYa+nj2P8wgLU8V9A9gjp75QxZK8MsL70kwy6vvupd4HHVVTB3LmzaJOuzKKWUKj109oqXjKGWMdKrYQwdHW05ACwHmhlDI2OIAoYCM4PVzqLizNO45x54/XVZWdabePCppyQv5MILYdWqQLdSKaWUKrxATpn9AlgMnGMMScZwqzGMMIYRjlMGAescOR1vAkOtxVpLBnAX8AOQAEx15HoUTzt3Qv36MPPM4yJjZEbLHXfAiy/CE08UfE2LFrBwoczavegi+OKLM26GUkopFRCBnL1yTQHH3wbezuPYbGB2INrld4mJUtu8kPkcORkjOR3p6dKLUaaMLGmfn44dYeVKGDy4cOu6KKWUUkUh2LNXQp9z5oqP02XzExYms1jS0+GxxyS59L//zf+amjWlvHp4uLz+6Sdo3RqqV/dbs5RSSoUiY/oCbwDhwEdY+3yO4wOBp4AsIAO4F2t/C0RTNOg4U4mJULmy/NT3o/BwWaclPV2m1UZFSb5HQdcApKTAkCEyqWb6dGjf3q9NU0opFSqMcRbcvAQpQbEcY2ZirXvtq5+AmVhrMaY1MBWIC0RztLTUmUpIgLg47+e4+iAiAj77DK64Qma0vP++d9eVLw8//ihN6twZPv3U701TSikVGjoCW7B2K9amw+mCmy7WpuCayhpDPmUqzlSJ6umIjY1lwYIFRfqeDevXJzMmhp0BfN+RI6FfPzhyRMqmV63q3XUffwxbt0JysgQv9esHrIlKKaWCoBpEYMwKt11jsXas22vvCm4acwXwHFADuDQATZW30VVmQ8PJkzBwoPRgfPqprNfijYwMmX6bng5vvhnYNiqllCpaBdbpMOZqoA/W3uZ4PQzoiLUj8zi/KzAaa//l/9aWsJ6OIpeWJokUkZEBf6syZSQ/o39/uOkmyfEYMqTg6yIi4OWXXTU//vxTApBOxbuwvFJKKf9IAtz7ueshS494Zu1CjGmCMdWwNtnfjdGcjjMxaRLExMCOHUXydmXLSjmQzp3huuvg66+9v9aZcnLffdC1qwy9KKWUKvGWA80wphHGeC64aUxTjOOnhDHtgCikWKffadBxJhIT5ad53bpF9pYxMfDdd1KbY+hQmDXLt+u//FKWibntNilClp4emHYqpZQqBqzNVXATa9djzAiMcRbrvApYhzGrkJkuQwhQ7oXmdJyJAQNg+3ZYu7bo3tPhyBG45BJYvVp6P/r08f7azEwpOPbCC1I+fdYsiI0NXFuVUkoFhq69UpokJvq1KJgvKlWCH36QMuiXXw7vvivBhDfCw+H552HqVCkeVrFiQJuqlFJKARp0FF5amsxHjQtI/RSvVKkiK8x27ixL23foAL/5UEPu6qvhm28k2XTvXhg3zrtF5pRSSqnC0KCjsDIy4JlnID4+qM2oVk0Cjy+/hAMHoEsXuP562JV3bnI2zgTTt96CW26RXI+0tMC1VymlVOmlOR0lyPHjMmzy0ksyi3f0aCmdHhVV8LWZmTBmDDz9NJx/vsyMqVcv4E1WSil1BkItp0ODjsLavl1+mtepUzTv54O//oJRo+Dbb+Gcc+CNN7xPNJ0+HW64QdZt+eWXoI4eKaWUKkCoBR06vFJYDz8MF18c7FZ41KSJzGiZPRuysqBvX1m/Zdu2gq+94gpYtgyaNnXNBN6/X3M9lFJKnTkNOgrLudBbMRYfL7N5n3tO8j5atIAnnoDU1Pyva95cElIrVJBhl27d4KKLYM4cDT6UUkoVngYdhZGVBRs3Bm26rC/KlJG1VzZulF6MJ5+U4OPrr/MPIJwJptbKCre7dkkQc8EFUpxMgw+llFK+0qCjMHbskCkexbynw13dulK1fcECqctx1VXQu7d02OQnIgKGD4fNm2HsWNi3T9Z/mTkz/+uUUkqpnDToKAznT+oQ6OnIqVs3+OMPmSK7YgW0bg333w9Hj+Z/XVQU3H47bNoEn38OlzoWPv7iC0lY1Z4PpZRSBdHZK4Wxezf89BNcdllIl/Pcvx8eeUQWf6tZU8qiX389hHkZiloruR5LlkC7djJF97LLXEMzSimlAktnr5QGtWvLT+cQDjhASqB/+CEsXQpnnQU33ijFxf74w7vrjYGFC6WS6ZEjUo69XTv49deANlsppVSI0qCjML7/HjZsCHYr/Ob882HRIvjkE9iyRcqpjxghHToFiYyEm26SZWg+/RRSUqRYK8gsmaysgDZdKaVUCAnY8IoxfAL0B/ZZS0sPx68DHnS8TAHusJbVjmPbgWNAJpBhLR28ec8iG16pVk0yMT/4IPDvVcQOH4b//U9yPjIzoX17mbXSrx907CiLxeUnM1OGZ4yRaqjz58Pjj8sfl7fDNkoppbyjwysu44G++RzfBnSzltbAU8DYHMd7WMt53gYcRWb/flnkJIRmrviicmV47TXpyHn6aYiOhmefldyNGjXgmmtgwgRZIM6T8HBXTkfnzpCeDoMHS8LqlCner4SrlFKq5AlY0GEtC4GD+RxfZC2HHC+XAKGx0kdiojyG4MwVX5x9Njz6qBQJS06WgOGyy6Tn4sYboVYtGYYZPRoWL/YcTAweDOvXy1TdrCwYOhSeekqOWaszXpRSqrQpLh3etwLfu722wI/GsNIYhgepTZ45p8uW0J4OT6pUkQBi3DgpErZypasX5JlncveC7NvnujY8XPavXQuTJ0uyKUiy6dlnw4MPStl1DUCUUqrkC+iUWWNoCMzylNPhdk4P4F3gYms54NhXx1p2GUMNYC4w0tFz4un64SCBSVRUTPuTJwOc0zFqlORypKRokgJw6JCUWP/+e9mcwy4dOkguSHy851yQRYskd+TnnyXxtF49uPJK2Ve5cpF/DKWUCkmhltMR1KDDGFoD04F4a9mUxzljgBRrebmg9yuSRNLkZNi6VX6SqmyysmDVKlcAsnix7IuNleqn8fGy+FyNGq5rDh6U4mJffy3FyrZvlxkx06dDTAz06CGvlVJK5aZBh/vN8wk6jKEB8DNwg7UsctsfA4RZyzHH87nAk9Yyp6D3K9Kl7VWBDh509YLMmSO9IMZAp04wYIBsLVu6Ek9PnXIFGG3bSgBTubLkkjjLtkdHB+vTKKVU8aNBh/PGhi+A7kA1YC/wBBAJYC3vG8NHwFXADsclGdbSwRgaI70fABHAJGt5xpv3DHjQkZoqUzuuvLLEJ5L6m7MX5LvvpGdj+XLZ37ChrOVy2WVSoj0qSvanpcGPP8K0abLOy+HDUo/ts8/keGoqlCsXhA+ilFLFiAYdQRTwoOPPP6Xk5pdfwqBBgXufUmD3bglAZs6EefPgxAmoUAH69JEekH79pBwKSA/I/PkyTNOhg6z/0qaNnHvVVRK0VKkS3M+jlFLBoEFHEAU86Jg0Ca67TqZitMwzN1b5KDVVEkpnzoRZsyQgCQuTWTHOYZi4ONcwzPbt0uH09deQlCQr4XbsCB99JB1Q1ur6L0qp0kGDjiAKeNAxerTMEU1NhTJlAvc+pVhWlqz98u23EoSsWiX7mzSRIZgBA+DiiyX3IytLhmm++QZ++UWuqVoVXnpJpud27SrbxRfLOjNKKVXSaNARRAEPOq6+Wn4Kbt4cuPdQ2ezcKb0fM2dKb0h6uiSX9u0rAUh8fO6hlUmTpNdj8WLJDQFJTF2xQnpQNB9EKVVSaNARRAEPOtq2hfr15SegKnIpKTIb5ttvJRDZv1/qf1x8seR4NGwoq+U2bChbTIwUMvv1V6lc/+KLcp+LLpKZNM6ekC5dpCdFh2SUUqFGg44gCnjQkZEBR49KRqMKqsxMqWT67bcyHXfTJsj51VeokD0IcT5ftkzKsy9dKsEIwLBhUk0V5F5Nm2rtN6VU8adBRxBpnY7Sy1qpC7J9O+zYIY85nx89mv2acuWgdm2p/XHWWTJlNzYWbr9dhnAuvhguuEC2jh0liFFKqeJEg44gCmjQsWiRFIkYMwZq1gzMe6iAOnw4/6Dk0KHs54eFSbIqwMiR8PjjcPIkzJ4tgci55+Yu766UUkVJg44gCmjQ8eKLsjrZoUO6OEgJdfRo9iBk7VpJRt2wwRV8VK8uuSQgPSQdOkiOyKhRsvKuUkoVpVALOiKC3YCQkZAgP1U04CixKlaEVq1kc3f8uCSkLlsmeSCLFslqu2lp8Pvv8NtvkpjavTv8/TesWQMXXijl3tu105kySinlpD0d3rrwQihbVuZtqlJv924JQpYtk96QlStdOSPGSI4JyBDNeedJPZGwMElcrVRJCpoppdSZCrWeDg06vGGtFIO49lp4913/31+FvKws2LjR1Rvy++8yQyYzU47Xry/JqCtWSBXVWrWgQQNo3FiCkj59oHx5SVYtX15qz+kUXqVUQTToCKKABR2HD0uNjvvug7vu8v/9VYl04oQs1+MMRJYtg61bvbvWGOlYK19eRvQqVnQFJM7N/XXDhpLY2rSpa9E8pVTJ51XQYUxf4A0gHPgIa5/Pcfw64EHHqxTgDqxd7f/WatDhG13UQ52h1FQ4dkwKnaWkQHIy7NsnZd2PHpWOtH/+kWRVZy9J48Zwzjly3caNsi8zU2bS5PzrHhEBzZpBixau7dxz4eyztXK/UiVRgUGHMeHAJuASIAlYDlyDtRvczrkISMDaQxgTD4zB2k4Baa8GHUoVP5mZsG2b5C/Xri2zZJKSJIg4dsx1XuXKshzQhRdK3sh330nHXFKSzMBxzroJC5NekJzByDnnSI+KUio0eRF0XIgEEX0crx8GwNrn8ji/CrAOa+v6u62gs1e88+yzsG6dLOqhVBEID5cgoWlT17569eDIEekJSUhwbS1byujf0aPw73+7zq9QAerWlSWDrJWF9JyL6Tl7UYyRnpScwUhcnJSRV0qFvLrATrfXSUB+vRi3At8HqjElKuiIjY1lwYIFfr9v66+/JuL4cf4IwL2VKozISGjdWrasLFiwQAKL77+XYRfnlpYmwUrZshKYbNsm1xsjQzFhYVJvJD1dzt2/X+61YIFrho1zRNGY7M+9OZZzX1iYDPNER7s2LbCmVOFVgwiMWeG2ayzWjnV77SknwPMQhzE9kKDjYv+1MLsSFXQcPHiQ7t27+//Ge/ZAz56BubdSRcQ5Xfevv7Jvs2ZJj8gzz8Bjj8m5FStKT0e5clIOPjxcysyfOCFBgzNZNTPTuy0rSx5TUyWZ9tQpV7tq14bmzWWLi3M9r11bU6iUKkgyZGBth3xOSQLqu72uB+zKdZYxrYGPgHisPeDXRrq/jeZ0FODYMfkf+Nln4eGH/XtvpYqRv/6CJUtcwciOHVIEbf166Vn5z3+yzxivXl3WrFm2TIKD2bMlPq9b17VVrpw7cDh1ypWvkpAAiYmu5+75KhUrShDiHojExcmKwFrnRCnhRU5HBJJI2gv4B0kkvRZr17ud0wD4GbgBaxcFtL0adBRg+XIpsDB9Olx+uX/vrVQI2b5dAoR//nFtqamyJBHAZZdJvoi7Zs1k1V6AV16RmToNGrhW/T3rLNdCetZK0TX3QMT5uMvt97LISMl1cQ9EmjWTYKRqVe0dUaWLl1Nm+wGvI1NmP8HaZzBmBADWvo8xHwFXATscVxTUe1L49mrQUYDFi+G//4Xx47Nn9Smlsjl5UoID96AkLAzuvVeODxgAP/4o+SNOnTpJ7wrA/ffLEIwzGGnYEBo1kt6SI0dkunDOgGTLFldSLEjvSJMmnrd69TR/RJU8WhwsiHTKrFLFW1aWrFPjXFivbFkYOFCOdekixdTc/wkPGgRffinPr71WCgO795I0aCBrMG7ZkjtXZfv27LkjUVFyraeApFEjnTqsQpMGHUEUkKBDC4IpVWSslYTXHTtkq1YNunaV4KFjRwkkDh92nT9qFLz6qgQqffpI8qlzq1lTAhNwBSXbtrmCEudaOU5162YPRGrWdCXA+rJlZOR9zFqIjZV8mOrVoUaN7I8VK+p/N8o3GnQ4b2z4BOgP7LOWlh6OG6Qsaz8gFbjJWv5wHMtWstVans95vScBCTrat5flQ195xb/3VUoVytGjrqCkfn1o00ZyRYYOleGd3btdAcWrr0pgsmmT1B+pVcsVlFSpIgFNdDRs2ACrV8t9du6Ue/giPNy7DWQWUEqK5/tEReUOSDwFJ87nFSpokFLaadDhvLGhK1LDfUIeQUc/YCQSdHQC3rCWTsbgsWSrtWzIeY+c/B50nDolcwYfeEDmEyqlQkJqqgQOlSpJb8muXfDWW7LPfXvvPRnC+fln6NVLrjVGfqhXrSqT1i64QAKcn3+GOnUkcKlTR3pGKlWSvBVff/CfOCE1Ufbvl0An5/Oc+/L6by0qSoKPqlWlB8XbrWxZDVZKilALOgI28cxaFhpDw3xOGYgEJBZYYgyVjaE20BDYYi1bAYxhsuPcAoMOv9uyRfpKmzcv8rdWShVeuXIyROJUpw4857noMwCtWskEtZxBSePGEmT88AM88kju65Ytg/PPl+nC48ZJD4qzN6VWLejWTdqSU9myko/SoIF3n8cZpOQVlBw4ID0oCQnyeOBA9nyWnMqUKTgwqVpVhphq1ZJHHfpR/hDM2e6eSrPWzWN/QBaeKVBiojzGxQXl7ZVSRaN69fxnxA8bBv36SR2SPXskINmzR4ISkB/ya9fC3Lky08Zp1y4JOp59VnpaataU96pWTX6ov/yyDO+sXi33q1rVdax8edcPeV+DFGult+fgQe+2bdtg5Up5nprq+Z7R0a4ApKDH8uW9a6cqfYIZdORVmtX7kq2AMQwHhkMAlvROSJBHDTqUKtXCwly5FK1a5T4+bJhsIL0SzuCkRg3Z16oV9O8v+5KTZbjm0CF48005/u67MHZs9ntWquRKmn3+eVixIntQUrcuDBkix/fuld6LSpVc5edjYmSrXx+fpKVJ2/bvl/vu3Svtdn/cuhUWLZLP4mmEPiYm74AkNlbyady3ihV1OnNpEcygI6/SrFF57PfIWsYCYwFiYvIOTgqleXMYMULDdqWU18qWlSm4jRq59g0YIFteHn8cbrhBekySk+XRvZ7JoUPyO5DzWGam3N8ZdFx/PcybJ4XTqlWTrUMH+OQTOT5unPRgVKvm6mmpVcsVFLmLjnYl2xYkI8MVnOQMTJyPiYmyls/Bg3nfxxgJPHIGI1WqSJ0WT/udxypXls+tQkNAp8w6cjpm5ZFIeilwF65E0jetpaMxeCzZai3rc94jJ63ToZQq6ayV2TnHjknBM5D1czZtkgAgOVm2OnXgnXfk+Lnnygwdd716SaDifH78uCsgqV5dCrdddZUcX7lSelHOZFpverrknxw6lH07fDj3vpzH0tLyv3flytmnS7vn1rhvJTEvJdQSSQM5e+ULoDtQDdgLPAFEAljL+44ps28DfZEpszdbywrHtdlKtlqLV1NH/Bp0WCuhedWq/rmfUkoFSUaG/HfmDEr275cg4pJL5Pjw4VIDxf34kCHw6afyX2G5cq4f/M7elOHDYcwYqWVyzz3yX6V70HL22a6g6Ew5h3zyClb27XMl/zpzbjwFKmXL5g5EPAUq1arJkFoo0KAjiPwadCQlyWDohx/Cbbf5555KKRUCrJVAJTJSns+Zkz0gSU6WGifDhkmvS6NGuYdPnnhCgpI9eyQtzjnsU7myBDy33CIF3Q4ehEmTZF/FivJYqZKrBH5h23/kSO7ZSO6bMzhxT/x1ioiQtpYrJ8NNhd3Kls29r0kT74auvBVqQYeu1ZgXZxKprreilCpljHHlSRgD8fF5n1uxouSZ5OxNqVtXjoeHS76KM2BxzpbZt0+Ob98OI0fmvu+nn8p1ixZJj4wzGHFuY8bAhRfKsNLXX0svhftWvboELQVVPEhNdQUg7ltysvSWnDghj87t6NHsr923jIyC/2xff116hkorDTry4gw6tEaHUkoVKCJCElNzJqdWr+6apeOJs6LskSPZt/bt5XiNGpLP737s8GEZ1gFYtw4efjj3fX/5RXpjvv9eftDnDEr69ZPgJTJSelWc05/PREZG3gGJc2vW7MzfJ5Rp0JGXxEQJkz2ldyullPKL8HDXdGRPmjbNfxWKK6+UsvLu03v37HH9vnjypAQpGzfK/pMnZf9ff0nQ8dprMnvIOa3Xub38svTirFghdSKdQz/Ox/r1cyelRkTIZEed8Jg3zenIS48e8rdz0SL/3E8ppVRQOXM99uyR3IrISFi4UHpDnMGKc9u+XWqf3HsvvPFG9vsYI70aYWFy/KuvsgckNWrAhAly7jffSF2WihWll+Pii/37mTSno6QYMaLkza1SSqlSzBhXbQ+nrl1ly8vo0fDvf0suh3N4JzXVNbulXTs55jyec0G/Tz6Bb7+V51dc4f+gI9RoT4dSSikVIKdOuYKS8HDvS9l7S3s6lFJKKQXIEE7VqlryySlEyp8opZRSKtRp0KGUUkqpIqFBh1JKKaWKhAYdSimllCoSGnQopZRSqkho0KGUUkqpIqFBh1JKKaWKhAYdSimllCoSGnQopZRSqkho0KGUUkqpIlGi1l4xxmQBJ/x4ywggw4/3Kw5K4meCkvm59DOFjpL4uUriZ4KS97nKWmtDpgOhRAUd/maMWWGt7RDsdvhTSfxMUDI/l36m0FESP1dJ/ExQcj9XqAiZ6EgppZRSoU2DDqWUUkoVCQ068jc22A0IgJL4maBkfi79TKGjJH6ukviZoOR+rpCgOR1KKaWUKhLa06GUUkqpIlHqgw5jTF9jzEZjzBZjzEMejhtjzJuO42uMMe2C0U5fGGPqG2PmG2MSjDHrjTH3eDinuzHmiDFmlWMbHYy2+sIYs90Ys9bR3hUejofid3WO23ewyhhz1Bhzb45ziv13ZYz5xBizzxizzm1frDFmrjFms+OxSh7X5vtvMJjy+FwvGWMSHX/HphtjKudxbb5/X4Mlj880xhjzj9vfsX55XBtq39UUt8+03RizKo9ri+V3VSJZa0vtBoQDfwGNgShgNdAixzn9gO8BA1wALA12u734XLWBdo7nFYBNHj5Xd2BWsNvq4+faDlTL53jIfVc52h8O7AHOCrXvCugKtAPWue17EXjI8fwh4IU8PnO+/waL4efqDUQ4nr/g6XM5juX797WYfaYxwP0FXBdy31WO468Ao0PpuyqJW2nv6egIbLHWbrXWpgOTgYE5zhkITLBiCVDZGFO7qBvqC2vtbmvtH47nx4AEoG5wW1UkQu67yqEX8Je1dkewG+Ira+1C4GCO3QOBTx3PPwUu93CpN/8Gg8bT57LW/mitdRaXWgLUK/KGnYE8vitvhNx35WSMMcBg4IsibZTKpbQHHXWBnW6vk8j9w9mbc4otY0xDoC2w1MPhC40xq40x3xtjzi3alhWKBX40xqw0xgz3cDykvytgKHn/pxhq3xVATWvtbpBAGKjh4ZxQ/85uQXrXPCno72txc5djyOiTPIbCQvm76gLstdZuzuN4qH1XIau0Bx3Gw76c03m8OadYMsaUB6YB91prj+Y4/AfSjd8GeAv4poibVxidrbXtgHjgP8aYrjmOh/J3FQVcBnzp4XAoflfeCuXv7FGknPbEPE4p6O9rcfIe0AQ4D9iNDEXkFLLfFXAN+fdyhNJ3FdJKe9CRBNR3e10P2FWIc4odY0wkEnBMtNZ+nfO4tfaotTbF8Xw2EGmMqVbEzfSJtXaX43EfMB3p7nUXkt+VQzzwh7V2b84DofhdOex1Dm85Hvd5OCckvzNjzI1Af+A6a63HH7xe/H0tNqy1e621mdbaLOBDPLc1VL+rCOBKYEpe54TSdxXqSnvQsRxoZoxp5PhNcygwM8c5M4EbHDMjLgCOOLuMiyvH+OXHQIK19tU8zqnlOA9jTEfk78KBomulb4wxMcaYCs7nSDLfuhynhdx35SbP38RC7btyMxO40fH8RmCGh3O8+TdYrBhj+gIPApdZa1PzOMebv6/FRo7cpyvw3NaQ+64c/gUkWmuTPB0Mte8q5AU7kzXYGzLjYROSlf2oY98IYITjuQHecRxfC3QIdpu9+EwXI92ea4BVjq1fjs91F7AeyUBfAlwU7HYX8JkaO9q62tHuEvFdOdpdDgkiKrntC6nvCgmYdgOnkN+IbwWqAj8Bmx2PsY5z6wCz3a7N9W+wuGx5fK4tSG6D89/W+zk/V15/X4vDlsdn+szxb2YNEkjULgnflWP/eOe/JbdzQ+K7KombViRVSimlVJEo7cMrSimllCoiGnQopZRSqkho0KGUUkqpIqFBh1JKKaWKhAYdSimllCoSGnQopZRSqkho0KGUUkqpIqFBh1JKKaWKxP8DOGEUWDtqmR8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "his = history.history \n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ln1 = ax.plot(his['loss'], 'b--',label='loss')\n",
    "ln2 = ax.plot(his['val_loss'], 'b-',label='val_loss')\n",
    "ax.set_ylabel('loss', color='blue')\n",
    "ax.tick_params(axis='y', colors=\"blue\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ln3 = ax2.plot(his['accuracy'], 'r--',label='accuracy')\n",
    "ln4 = ax2.plot(his['val_accuracy'], 'r-',label='val_accuracy')\n",
    "ax2.set_ylabel('accuracy', color='red')\n",
    "ax2.tick_params(axis='y', colors=\"red\")\n",
    "\n",
    "lns = ln1 + ln2 + ln3 + ln4 \n",
    "labels = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labels)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize using Tensorboard on the same jupyter notebook, we first need to load the TensorBoard extension. Then just calling the tensorboard with log file directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4200), started 0:22:06 ago. (Use '!kill 4200' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-81fc140ad5bc5824\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-81fc140ad5bc5824\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tf_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir tf_logs (started 0:22:22 ago; pid 4200)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir tf_logs (started 0:22:22 ago; port 6006, pid 4200).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-acde69081ed0bed9\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-acde69081ed0bed9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Control TensorBoard display. If no port is provided, \n",
    "# the most recently launched TensorBoard is used\n",
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">6. Playing around with different optimizers</span>\n",
    "In the following code, we try different optimizers to find the optimal one which has the best performance (evaluated on the validation set). \n",
    "It can be done easily by passing an specific optimizer when compiling model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluating with Nadam\n",
      "\n",
      "1500/1500 [==============================] - 0s 16us/sample - loss: 0.6324 - accuracy: 0.8093\n",
      "The valid accuracy is 0.809333324432373\n",
      "\n",
      "*Evaluating with Adam\n",
      "\n",
      "1500/1500 [==============================] - 0s 18us/sample - loss: 0.6159 - accuracy: 0.8160\n",
      "The valid accuracy is 0.8159999847412109\n",
      "\n",
      "*Evaluating with Adadelta\n",
      "\n",
      "1500/1500 [==============================] - 0s 18us/sample - loss: 0.6089 - accuracy: 0.8193\n",
      "The valid accuracy is 0.8193333148956299\n",
      "\n",
      "*Evaluating with Adagrad\n",
      "\n",
      "1500/1500 [==============================] - 0s 14us/sample - loss: 0.6056 - accuracy: 0.8193\n",
      "The valid accuracy is 0.8193333148956299\n",
      "\n",
      "*Evaluating with RMSprop\n",
      "\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 0.6163 - accuracy: 0.8180\n",
      "The valid accuracy is 0.8180000185966492\n",
      "\n",
      "*Evaluating with SGD\n",
      "\n",
      "1500/1500 [==============================] - 0s 14us/sample - loss: 0.6091 - accuracy: 0.8227\n",
      "The valid accuracy is 0.8226666450500488\n",
      "\n",
      "The best valid accuracy is 0.8226666450500488 with SGD\n"
     ]
    }
   ],
   "source": [
    "optimizer_names = [\"Nadam\", \"Adam\", \"Adadelta\", \"Adagrad\", \"RMSprop\", \"SGD\"]\n",
    "optimizer_list = [keras.optimizers.Nadam(learning_rate=0.001), keras.optimizers.Adam(learning_rate=0.001), keras.optimizers.Adadelta(learning_rate=0.001), \n",
    "                  keras.optimizers.Adagrad(learning_rate=0.001), keras.optimizers.RMSprop(learning_rate=0.001), keras.optimizers.SGD(learning_rate=0.001)]\n",
    "best_acc = 0\n",
    "best_i = -1\n",
    "for i in range(len(optimizer_list)):\n",
    "    print(\"*Evaluating with {}\\n\".format(str(optimizer_names[i])))\n",
    "    dnn_model.compile(optimizer=optimizer_list[i], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=30, validation_data=(X_valid, y_valid), verbose=0)\n",
    "    acc = dnn_model.evaluate(X_valid, y_valid)[1]\n",
    "    print(\"The valid accuracy is {}\\n\".format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_i = i\n",
    "print(\"The best valid accuracy is {} with {}\".format(best_acc, optimizer_names[best_i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">7. Fine-tuning the learning rate</span>\n",
    "Learning rate plays an important role when training a deep learning model. In the following code, we will try a simple greedy search to find a good learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluating with learning rate = 0.01\n",
      "\n",
      "1500/1500 [==============================] - 0s 10us/sample - loss: 0.6443 - accuracy: 0.8033\n",
      "The valid accuracy is 0.8033333420753479\n",
      "\n",
      "*Evaluating with learning rate = 0.005\n",
      "\n",
      "1500/1500 [==============================] - 0s 13us/sample - loss: 0.5313 - accuracy: 0.8387\n",
      "The valid accuracy is 0.8386666774749756\n",
      "\n",
      "*Evaluating with learning rate = 0.001\n",
      "\n",
      "1500/1500 [==============================] - 0s 17us/sample - loss: 0.5038 - accuracy: 0.8533\n",
      "The valid accuracy is 0.8533333539962769\n",
      "\n",
      "*Evaluating with learning rate = 0.0001\n",
      "\n",
      "1500/1500 [==============================] - 0s 11us/sample - loss: 0.4901 - accuracy: 0.8540\n",
      "The valid accuracy is 0.8539999723434448\n",
      "\n",
      "*Evaluating with learning rate = 1e-05\n",
      "\n",
      "1500/1500 [==============================] - 0s 18us/sample - loss: 0.4887 - accuracy: 0.8540\n",
      "The valid accuracy is 0.8539999723434448\n",
      "\n",
      "The best valid accuracy is 0.8539999723434448 with learning rate 0.0001\n"
     ]
    }
   ],
   "source": [
    "lr = [1e-2, 5e-3, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "best_acc = 0\n",
    "best_i = -1\n",
    "for i in range(len(lr)):\n",
    "    print(\"*Evaluating with learning rate = {}\\n\".format(str(lr[i])))\n",
    "    dnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr[i]), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=30, validation_data=(X_valid, y_valid), verbose=0)\n",
    "    acc = dnn_model.evaluate(X_valid, y_valid)[1]\n",
    "    print(\"The valid accuracy is {}\\n\".format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_i = i\n",
    "print(\"The best valid accuracy is {} with learning rate {}\".format(best_acc, lr[best_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">8. Save and Load Models</span>\n",
    "\n",
    "There are different ways to save TensorFlow models depending on the API you're using. As we used the Keras model in this tutorial, saving and loading it quite simple. It can be done by calling `model.save()` and `load_model()` methods. \n",
    "When calling `model.save()`, the entire model will be saved including: \n",
    "- The architecture, or configuration, which specifies what layers the model contain, and how they're connected.\n",
    "- A set of weights values (the \"state of the model\").\n",
    "- An optimizer (defined by compiling the model).\n",
    "- A set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True]]\n"
     ]
    }
   ],
   "source": [
    "# Saving the entire model to a directory\n",
    "dnn_model.save('models/my_model.h5')\n",
    "\n",
    "# Loading the model back \n",
    "from tensorflow import keras\n",
    "loaded_model = keras.models.load_model('models/my_model.h5')\n",
    "\n",
    "# Checking the loaded model \n",
    "print(dnn_model.predict(X_new) == loaded_model.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">Save model during training</span>\n",
    "\n",
    "One major disadvantage of the above saving method is that we cannot save the model during training but only when the training is finished. Therefore, it can be the case when the training was stopped/interrupted and we have to retrain again. To save model during training process, we can use the `ModelCheckpoint` callback allows you to continually save the model both during and at the end of training. \n",
    "Some important arguments of the `ModelCheckpoint` callback: \n",
    "- `filepath`: checkpoin directory \n",
    "- `save_weights_only`: if True, then only the model's weights will be saved (i.e., equal with model.save_weights(filepath)), else the full model is saved (i.e., equal with model.save(filepath) which saves: model' weight, model architecture, optimizer, etc.)\n",
    "- `save_best_only`: if True, it only saves when the model is considered the \"best\" and the latest best model according to the quantity monitored will not be overwritten. The \"best\" model is evaluated based on \"mode\" and \"monitor\". For example, if `monitor=val_accuracy` it means that validation accuracy is used to monitor the best checkpoint, and `mode` should be set to `max`. If `monitor=val_loss` it means that validation loss is used instead, and `mode` in this case should be `min`. \n",
    "\n",
    "More detail can be found in the link: \n",
    "https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "11968/12000 [============================>.] - ETA: 0s - loss: 0.8860 - accuracy: 0.7472\n",
      "Epoch 00001: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 70us/sample - loss: 0.8855 - accuracy: 0.7474 - val_loss: 0.9219 - val_accuracy: 0.7460\n",
      "Epoch 2/20\n",
      "10560/12000 [=========================>....] - ETA: 0s - loss: 0.8774 - accuracy: 0.7509\n",
      "Epoch 00002: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 59us/sample - loss: 0.8732 - accuracy: 0.7518 - val_loss: 0.9137 - val_accuracy: 0.7427\n",
      "Epoch 3/20\n",
      "11904/12000 [============================>.] - ETA: 0s - loss: 0.8621 - accuracy: 0.7543\n",
      "Epoch 00003: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 60us/sample - loss: 0.8630 - accuracy: 0.7536 - val_loss: 0.9200 - val_accuracy: 0.7373\n",
      "Epoch 4/20\n",
      "11872/12000 [============================>.] - ETA: 0s - loss: 0.8540 - accuracy: 0.7545\n",
      "Epoch 00004: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 58us/sample - loss: 0.8535 - accuracy: 0.7545 - val_loss: 0.9001 - val_accuracy: 0.7380\n",
      "Epoch 5/20\n",
      "10368/12000 [========================>.....] - ETA: 0s - loss: 0.8468 - accuracy: 0.7560\n",
      "Epoch 00005: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 57us/sample - loss: 0.8450 - accuracy: 0.7565 - val_loss: 0.8984 - val_accuracy: 0.7387\n",
      "Epoch 6/20\n",
      "10464/12000 [=========================>....] - ETA: 0s - loss: 0.8373 - accuracy: 0.7594\n",
      "Epoch 00006: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 58us/sample - loss: 0.8369 - accuracy: 0.7585 - val_loss: 0.8882 - val_accuracy: 0.7560\n",
      "Epoch 7/20\n",
      "10208/12000 [========================>.....] - ETA: 0s - loss: 0.8312 - accuracy: 0.7597\n",
      "Epoch 00007: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 56us/sample - loss: 0.8294 - accuracy: 0.7605 - val_loss: 0.8841 - val_accuracy: 0.7460\n",
      "Epoch 8/20\n",
      "11232/12000 [===========================>..] - ETA: 0s - loss: 0.8190 - accuracy: 0.7622\n",
      "Epoch 00008: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 57us/sample - loss: 0.8195 - accuracy: 0.7613 - val_loss: 0.8718 - val_accuracy: 0.7413\n",
      "Epoch 9/20\n",
      "11872/12000 [============================>.] - ETA: 0s - loss: 0.8104 - accuracy: 0.7631\n",
      "Epoch 00009: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 56us/sample - loss: 0.8112 - accuracy: 0.7627 - val_loss: 0.8697 - val_accuracy: 0.7473\n",
      "Epoch 10/20\n",
      "11232/12000 [===========================>..] - ETA: 0s - loss: 0.8033 - accuracy: 0.7645\n",
      "Epoch 00010: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 58us/sample - loss: 0.8043 - accuracy: 0.7646 - val_loss: 0.8637 - val_accuracy: 0.7493\n",
      "Epoch 11/20\n",
      "10816/12000 [==========================>...] - ETA: 0s - loss: 0.8044 - accuracy: 0.7665\n",
      "Epoch 00011: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 55us/sample - loss: 0.7993 - accuracy: 0.7662 - val_loss: 0.8557 - val_accuracy: 0.7547\n",
      "Epoch 12/20\n",
      "11072/12000 [==========================>...] - ETA: 0s - loss: 0.7880 - accuracy: 0.7685\n",
      "Epoch 00012: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 55us/sample - loss: 0.7891 - accuracy: 0.7682 - val_loss: 0.8520 - val_accuracy: 0.7573\n",
      "Epoch 13/20\n",
      "11648/12000 [============================>.] - ETA: 0s - loss: 0.7810 - accuracy: 0.7717\n",
      "Epoch 00013: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 60us/sample - loss: 0.7834 - accuracy: 0.7701 - val_loss: 0.8374 - val_accuracy: 0.7607\n",
      "Epoch 14/20\n",
      "10304/12000 [========================>.....] - ETA: 0s - loss: 0.7829 - accuracy: 0.7687\n",
      "Epoch 00014: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 59us/sample - loss: 0.7756 - accuracy: 0.7715 - val_loss: 0.8529 - val_accuracy: 0.7513\n",
      "Epoch 15/20\n",
      "10688/12000 [=========================>....] - ETA: 0s - loss: 0.7696 - accuracy: 0.7716\n",
      "Epoch 00015: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 57us/sample - loss: 0.7709 - accuracy: 0.7715 - val_loss: 0.8310 - val_accuracy: 0.7680\n",
      "Epoch 16/20\n",
      "10880/12000 [==========================>...] - ETA: 0s - loss: 0.7610 - accuracy: 0.7787\n",
      "Epoch 00016: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 88us/sample - loss: 0.7620 - accuracy: 0.7777 - val_loss: 0.8231 - val_accuracy: 0.7693\n",
      "Epoch 17/20\n",
      "10624/12000 [=========================>....] - ETA: 0s - loss: 0.7594 - accuracy: 0.7734\n",
      "Epoch 00017: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 57us/sample - loss: 0.7585 - accuracy: 0.7753 - val_loss: 0.8180 - val_accuracy: 0.7673\n",
      "Epoch 18/20\n",
      "10624/12000 [=========================>....] - ETA: 0s - loss: 0.7629 - accuracy: 0.7763\n",
      "Epoch 00018: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 59us/sample - loss: 0.7539 - accuracy: 0.7785 - val_loss: 0.8050 - val_accuracy: 0.7667\n",
      "Epoch 19/20\n",
      "11456/12000 [===========================>..] - ETA: 0s - loss: 0.7437 - accuracy: 0.7806\n",
      "Epoch 00019: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 59us/sample - loss: 0.7457 - accuracy: 0.7805 - val_loss: 0.8074 - val_accuracy: 0.7660\n",
      "Epoch 20/20\n",
      "11008/12000 [==========================>...] - ETA: 0s - loss: 0.7435 - accuracy: 0.7793\n",
      "Epoch 00020: saving model to ./checkpoints/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 55us/sample - loss: 0.7426 - accuracy: 0.7809 - val_loss: 0.7971 - val_accuracy: 0.7647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e70b6e5388>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tf.keras.callbacks.ModelCheckpoint callback that saves weights only during training\n",
    "checkpoint_path = \"./checkpoints/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "#dnn_model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "dnn_model.fit(x=X_train, y=y_train, batch_size=32, \n",
    "                        epochs=20, \n",
    "                        validation_data=(X_valid, y_valid), \n",
    "                       callbacks=[tensorboard_callback, # Callback for writing log \n",
    "                                 cp_callback]) # Callback for saving model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">Save model during training</span>\n",
    "If we only saved the model's weight, we need to recreate a same architecture before loading the model weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e70b708708>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we alreary created a model, therefore, we just need to load the weight \n",
    "# dnn_model = create_model() # skip this step\n",
    "dnn_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we saved the entire model (by set `save_weights_only=False`), then the pretrained model can be reloaded by `load_model` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.3 Two Approaches to Build Up Models with TensorFlow 2.x</span> <span style=\"color:red\">*** (moderately important)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two approaches to build up a model with tensorflow 2.x, a simple method using **Sequential API** and a more flexible method using **Functional API**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> Approach 1: Using `Sequential API`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=26, activation='softmax'))\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> Approach 2: Using `Functional API`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.layers.Input(shape=(16,)) #declare input layer\n",
    "h = Dense(units=10, activation= 'relu')(X)\n",
    "h = Dense(units=20, activation= 'relu')(h)\n",
    "h = Dense(units=15, activation= 'relu')(h)\n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also declare a class inherited from `tf.keras.Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDNN(tf.keras.Model):\n",
    "    def __init__(self, n_classes= 26):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dense1 = tf.keras.layers.Dense(units=10, activation= 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=20, activation= 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=15, activation= 'relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(units=self.n_classes, activation= 'softmax')\n",
    "    \n",
    "    def call(self,X): #X is the input, method call specifies how to compute the output from the input X\n",
    "        h = self.dense1(X)\n",
    "        h = self.dense2(h)\n",
    "        h = self.dense3(h)\n",
    "        h = self.dense4(h)\n",
    "        return h\n",
    "dnn_model = MyDNN(n_classes= 26)\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.4 Other approaches to Train a Model with TensorFlow 2.x</span> <span style=\"color:red\">*** (moderately important)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main approaches to training a model with Tensorflow 2.x. The simplest method is the `fit` method as we did before. This method automatically helps us to process data when training (e.g., split an entire dataset into multiple mini-batches), applies callback methods such as saving model or writing TensorBoard and monitors validation performance. \n",
    "\n",
    "However, some projects require more handly on training process (for example, doing data augmentation in self-supervised learning or training a generative model that we will learn later in this unit). In this case, we need an ability/understanding to train a model manually. In Tensorflow 2.X, we can do that with `train_on_batch` method. Basically, we will need to *(1) manually split entire dataset into mini-batches and applied data augmentaion (if any)* and *(2) feed training data to `train_on_batch` method*. It returns a training loss (which is pre-defined when compiling model) and an updated model. \n",
    "\n",
    "The following code is a simple example (without any data-augmentation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train acc=0.1887, train loss=2.7509 | valid acc=0.2093, valid loss= 2.7324\n",
      "Epoch 2: train acc=0.2895, train loss=2.2996 | valid acc=0.2960, valid loss= 2.2943\n",
      "Epoch 3: train acc=0.3925, train loss=2.0406 | valid acc=0.3940, valid loss= 2.0456\n",
      "Epoch 4: train acc=0.4502, train loss=1.8343 | valid acc=0.4547, valid loss= 1.8526\n",
      "Epoch 5: train acc=0.5048, train loss=1.6744 | valid acc=0.5053, valid loss= 1.7030\n",
      "Epoch 6: train acc=0.5466, train loss=1.5491 | valid acc=0.5360, valid loss= 1.5848\n",
      "Epoch 7: train acc=0.5839, train loss=1.4383 | valid acc=0.5780, valid loss= 1.4798\n",
      "Epoch 8: train acc=0.6158, train loss=1.3343 | valid acc=0.6020, valid loss= 1.3766\n",
      "Epoch 9: train acc=0.6431, train loss=1.2398 | valid acc=0.6293, valid loss= 1.2817\n",
      "Epoch 10: train acc=0.6686, train loss=1.1601 | valid acc=0.6513, valid loss= 1.2032\n",
      "Epoch 11: train acc=0.6864, train loss=1.0942 | valid acc=0.6647, valid loss= 1.1398\n",
      "Epoch 12: train acc=0.7018, train loss=1.0396 | valid acc=0.6753, valid loss= 1.0883\n",
      "Epoch 13: train acc=0.7132, train loss=0.9959 | valid acc=0.6900, valid loss= 1.0481\n",
      "Epoch 14: train acc=0.7228, train loss=0.9624 | valid acc=0.6960, valid loss= 1.0174\n",
      "Epoch 15: train acc=0.7297, train loss=0.9351 | valid acc=0.7073, valid loss= 0.9927\n",
      "Epoch 16: train acc=0.7355, train loss=0.9126 | valid acc=0.7160, valid loss= 0.9720\n",
      "Epoch 17: train acc=0.7409, train loss=0.8934 | valid acc=0.7233, valid loss= 0.9546\n",
      "Epoch 18: train acc=0.7449, train loss=0.8772 | valid acc=0.7307, valid loss= 0.9404\n",
      "Epoch 19: train acc=0.7480, train loss=0.8631 | valid acc=0.7380, valid loss= 0.9277\n",
      "Epoch 20: train acc=0.7506, train loss=0.8506 | valid acc=0.7393, valid loss= 0.9164\n"
     ]
    }
   ],
   "source": [
    "n_epochs =20\n",
    "batch_size = 64\n",
    "for epoch in range(n_epochs):\n",
    "    for idx_start in range(0, X_train.shape[0], batch_size):\n",
    "        idx_end = min(X_train.shape[0], idx_start + batch_size)\n",
    "        X_batch, y_batch = X_train[idx_start:idx_end], y_train[idx_start:idx_end]\n",
    "        train_loss_batch = dnn_model.train_on_batch(X_batch, y_batch)  #return the batch loss\n",
    "        \n",
    "    train_loss, train_acc = dnn_model.evaluate(x= X_train, y= y_train, batch_size= 64, verbose= 0)\n",
    "    valid_loss, valid_acc = dnn_model.evaluate(x= X_valid, y= y_valid, batch_size= 64, verbose= 0)\n",
    "    print('Epoch {}: train acc={:.4f}, train loss={:.4f} | valid acc={:.4f}, valid loss= {:.4f}'.format(epoch +1, \n",
    "                                                                                                        train_acc, \n",
    "                                                                                                        train_loss, \n",
    "                                                                                                        valid_acc, \n",
    "                                                                                                        valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> Additional Exercises </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write your own code to save a trained model to the hard disk and restore this model, then use the restored model to output the prediction result on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Insert new code to the above code to enable outputting to TensorBoard the values of `training loss`, `training accuracy`, `valid loss`, and `valid accuracy` at the end of epochs. You can refer to the code [here](https://www.tensorflow.org/tensorboard/get_started)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write code to do regression on the dataset `cadata` which can be downloaded [here](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html). Note that for a regression problem, you need to use the `L2` loss instead of the `cross-entropy` loss as in a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the problem in this tutorial, however, using a much deeper network (i.e., $16 \\rightarrow 100 (ReLU) \\rightarrow 200 (ReLU) \\rightarrow 200 (ReLU) \\rightarrow 100 (ReLu) \\rightarrow 26$). Applying callback methods to save the model on training and writing a TensorBoard. Visualize `training loss`, `training accuracy`, `valid loss`, and `valid accuracy`. Provide observation and explanation of any issue if happen (hint, overfitting issue). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Build up a more complex feedforward neural network with `Functional API` method  as shown in figure below. The network splits into two branches and then merges in the last layer. The concatenate operation is in the last dimenstion (for example, two arrays [10,15], [10,15] will be concatenated to an array [10,30]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/feed-forward-2branches.PNG\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
